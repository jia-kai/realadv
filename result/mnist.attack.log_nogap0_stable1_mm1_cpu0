preprocessing on output/mnist/1212.model
adv_loss=4.947185516357422e-06 adv_loss_mm=4.410743713378906e-06 inp_loss=4.273809432983398 gap=-1.518417445762958
preprocessing on output/mnist/1459.model
adv_loss=3.0994415283203125e-06 adv_loss_mm=3.159046173095703e-06 inp_loss=4.1296234130859375 gap=-1.0982149079709458
preprocessing on output/mnist/1461.model
adv_loss=3.337860107421875e-06 adv_loss_mm=3.993511199951172e-06 inp_loss=3.3484535217285156 gap=-2.074641341689596
preprocessing on output/mnist/2641.model
adv_loss=1.4603137969970703e-06 adv_loss_mm=2.294778823852539e-06 inp_loss=3.1373472213745117 gap=-2.2001739081808616
preprocessing on output/mnist/2782.model
adv_loss=4.172325134277344e-06 adv_loss_mm=3.039836883544922e-06 inp_loss=3.4540226459503174 gap=-0.03957562719990185
preprocessing on output/mnist/3860.model
adv_loss=9.5367431640625e-07 adv_loss_mm=1.5497207641601562e-06 inp_loss=3.865034341812134 gap=-3.673972438462156
preprocessing on output/mnist/3966.model
adv_loss=1.6987323760986328e-06 adv_loss_mm=1.6391277313232422e-06 inp_loss=2.7201294898986816 gap=-5.0190233333916646e-08
preprocessing on output/mnist/41.model
adv_loss=2.0265579223632812e-06 adv_loss_mm=2.384185791015625e-06 inp_loss=2.5272533893585205 gap=-1.925067271937266e-07
preprocessing on output/mnist/4798.model
adv_loss=1.7285346984863281e-06 adv_loss_mm=2.2649765014648438e-06 inp_loss=3.2024996280670166 gap=-0.8083748030881506
preprocessing on output/mnist/6327.model
adv_loss=1.6987323760986328e-06 adv_loss_mm=1.5795230865478516e-06 inp_loss=3.296889305114746 gap=-2.081276688754929e-07
preprocessing on output/mnist/6576.model
adv_loss=2.7418136596679688e-06 adv_loss_mm=1.6689300537109375e-06 inp_loss=2.962254524230957 gap=-1.6094605991540831
preprocessing on output/mnist/6791.model
adv_loss=1.5050172805786133e-06 adv_loss_mm=2.1904706954956055e-06 inp_loss=3.855414390563965 gap=-0.09270705339313404
preprocessing on output/mnist/6929.model
adv_loss=1.1771917343139648e-06 adv_loss_mm=1.5944242477416992e-06 inp_loss=4.787815093994141 gap=-1.845350300828507
preprocessing on output/mnist/7186.model
adv_loss=4.76837158203125e-07 adv_loss_mm=1.5497207641601562e-06 inp_loss=3.554492473602295 gap=-7.865661580616019e-07
preprocessing on output/mnist/850.model
adv_loss=1.6689300537109375e-06 adv_loss_mm=2.1457672119140625e-06 inp_loss=3.725200653076172 gap=-2.680255589217079e-06
preprocessing on output/mnist/8571.model
adv_loss=3.5762786865234375e-06 adv_loss_mm=2.6226043701171875e-06 inp_loss=3.511122703552246 gap=-7.943013895155949e-07
preprocessing on output/mnist/890.model
adv_loss=8.344650268554688e-07 adv_loss_mm=1.5497207641601562e-06 inp_loss=2.5032906532287598 gap=-1.022442080828036e-07
preprocessing on output/mnist/9285.model
adv_loss=1.9073486328125e-06 adv_loss_mm=3.2186508178710938e-06 inp_loss=2.9720473289489746 gap=-0.48362446971144474
working on output/mnist/3860.model with loss=1.5497208e-06
#0: loss: 1.54972e-06 -> 1.07288e-06 diff=4.77e-07,4.77e-07 Linf=1.931e-07
#2: loss: 1.07288e-06 -> 8.34465e-07 diff=7.15e-07,7.15e-07 Linf=1.931e-07
#2: loss: 8.34465e-07 -> 3.57628e-07 diff=1.19e-06,1.19e-06 Linf=1.959e-07
working on output/mnist/7186.model with loss=1.5497208e-06
#0: loss: 1.54972e-06 -> 1.31130e-06 diff=2.38e-07,2.38e-07 Linf=2.086e-07
#1: loss: 1.31130e-06 -> 1.07288e-06 diff=4.77e-07,4.77e-07 Linf=3.874e-07
#34: loss: 1.07288e-06 -> 9.53674e-07 diff=5.96e-07,5.96e-07 Linf=3.874e-07
#36: loss: 9.53674e-07 -> 2.38419e-07 diff=1.31e-06,1.31e-06 Linf=4.470e-07
#99: loss: 2.38419e-07 -> 1.19209e-07 diff=1.43e-06,1.43e-06 Linf=4.470e-07
#121: loss: 1.19209e-07 -> 0.00000e+00 diff=1.55e-06,1.55e-06 Linf=4.470e-07
#130: loss: 0.00000e+00 -> -2.38419e-07 diff=1.79e-06,1.79e-06 Linf=4.470e-07
conv [-8.2  -1.35 -5.06 -2.56 -4.39 -1.35 -5.48 -5.48 -2.65 -3.  ] l=1 cw=1.67e-06
mm   [-8.2  -1.35 -5.06 -2.56 -4.39 -1.35 -5.48 -5.48 -2.65 -3.  ] l=5 cw=-2.38e-07
test acc: 98.57%
working on output/mnist/890.model with loss=1.5497208e-06
#0: loss: 1.54972e-06 -> 1.07288e-06 diff=4.77e-07,4.77e-07 Linf=2.384e-07
#0: loss: 1.07288e-06 -> 9.53674e-07 diff=5.96e-07,5.96e-07 Linf=2.384e-07
#0: loss: 9.53674e-07 -> 7.15256e-07 diff=8.34e-07,8.34e-07 Linf=2.384e-07
#15: loss: 7.15256e-07 -> 4.76837e-07 diff=1.07e-06,1.07e-06 Linf=3.426e-07
#164: loss: 4.76837e-07 -> 3.57628e-07 diff=1.19e-06,1.19e-06 Linf=3.426e-07
#305: loss: 3.57628e-07 -> 1.19209e-07 diff=1.43e-06,1.43e-06 Linf=3.426e-07
#724: loss: 1.19209e-07 -> 0.00000e+00 diff=1.55e-06,1.55e-06 Linf=3.426e-07
working on output/mnist/6327.model with loss=1.5795231e-06
#0: loss: 1.57952e-06 -> 9.83477e-07 diff=5.96e-07,5.96e-07 Linf=1.864e-07
#0: loss: 9.83477e-07 -> 8.64267e-07 diff=7.15e-07,7.15e-07 Linf=2.086e-07
#2: loss: 8.64267e-07 -> 6.85453e-07 diff=8.94e-07,8.94e-07 Linf=2.086e-07
#2: loss: 6.85453e-07 -> 3.27826e-07 diff=1.25e-06,1.25e-06 Linf=2.086e-07
#3: loss: 3.27826e-07 -> 2.68221e-07 diff=1.31e-06,1.31e-06 Linf=2.086e-07
#3: loss: 2.68221e-07 -> 1.49012e-07 diff=1.43e-06,1.43e-06 Linf=3.652e-07
#258: loss: 1.49012e-07 -> -2.98023e-08 diff=1.61e-06,1.61e-06 Linf=3.652e-07
#269: loss: -2.98023e-08 -> -8.94070e-08 diff=1.67e-06,1.67e-06 Linf=3.652e-07
conv [-3.97 -4.93 -4.93 -4.77 -5.1  -0.31 -2.56 -7.34 -0.31 -5.6 ] l=8 cw=1.52e-06
mm   [-3.97 -4.93 -4.93 -4.77 -5.1  -0.31 -2.56 -7.34 -0.31 -5.6 ] l=5 cw=-8.94e-08
test acc: 98.57%
working on output/mnist/6929.model with loss=1.5944242e-06
#0: loss: 1.59442e-06 -> 1.47521e-06 diff=1.19e-07,1.19e-07 Linf=2.384e-07
#0: loss: 1.47521e-06 -> 1.41561e-06 diff=1.79e-07,1.79e-07 Linf=2.384e-07
#0: loss: 1.41561e-06 -> 1.23680e-06 diff=3.58e-07,3.58e-07 Linf=2.384e-07
#0: loss: 1.23680e-06 -> 1.11759e-06 diff=4.77e-07,4.77e-07 Linf=2.384e-07
#1: loss: 1.11759e-06 -> 8.19564e-07 diff=7.75e-07,7.75e-07 Linf=3.576e-07
#3: loss: 8.19564e-07 -> 7.59959e-07 diff=8.34e-07,8.34e-07 Linf=4.172e-07
#3: loss: 7.59959e-07 -> 7.00355e-07 diff=8.94e-07,8.94e-07 Linf=4.172e-07
#5: loss: 7.00355e-07 -> 6.40750e-07 diff=9.54e-07,9.54e-07 Linf=4.172e-07
#5: loss: 6.40750e-07 -> 2.83122e-07 diff=1.31e-06,1.31e-06 Linf=4.172e-07
#18: loss: 2.83122e-07 -> 4.47035e-08 diff=1.55e-06,1.55e-06 Linf=4.172e-07
#674: loss: 4.47035e-08 -> -1.49012e-08 diff=1.61e-06,1.61e-06 Linf=4.172e-07
#842: loss: -1.49012e-08 -> -7.45058e-08 diff=1.67e-06,1.67e-06 Linf=3.576e-07
conv [-5.97 -6.51 -5.8  -5.91  0.19 -6.92 -4.68 -5.63  0.19 -3.06] l=4 cw=1.36e-06
mm   [-5.97 -6.51 -5.8  -5.91  0.19 -6.92 -4.68 -5.63  0.19 -3.06] l=8 cw=-7.45e-08
test acc: 98.14%
verification of original model failed: {'ObjectiveBound': -1.012973834979558e-06,
 'ObjectiveValue': -1.012973834979558e-06,
 'PredictedIndex': 5,
 'SolveStatus': 'Optimal',
 'SolveTime': 21.79437494277954,
 'TargetIndexes': array([ 1,  2,  3,  4,  6,  7,  8,  9, 10]),
 'TighteningApproach': array([[108],
       [112]], dtype=uint16),
 'TotalTime': 32.257155368,
 'robust': False,
 'status_known': True}
retrying with new gap -1.8453501462936401 ...
conv [-5.97 -6.51 -5.8  -5.91  0.19 -6.92 -4.68 -5.63  0.19 -3.06] l=4 cw=1.48e-06
mm   [-5.97 -6.51 -5.8  -5.91  0.19 -6.92 -4.68 -5.63  0.19 -3.06] l=4 cw=4.47e-08
test acc: 98.14%
working on output/mnist/3966.model with loss=1.6391277e-06
#0: loss: 1.63913e-06 -> 1.54972e-06 diff=8.94e-08,8.94e-08 Linf=1.795e-07
#0: loss: 1.54972e-06 -> 1.51992e-06 diff=1.19e-07,1.19e-07 Linf=1.795e-07
#0: loss: 1.51992e-06 -> 1.25170e-06 diff=3.87e-07,3.87e-07 Linf=1.815e-07
#0: loss: 1.25170e-06 -> 1.01328e-06 diff=6.26e-07,6.26e-07 Linf=1.902e-07
#1: loss: 1.01328e-06 -> 9.53674e-07 diff=6.85e-07,6.85e-07 Linf=1.902e-07
#2: loss: 9.53674e-07 -> 6.25849e-07 diff=1.01e-06,1.01e-06 Linf=3.495e-07
#2: loss: 6.25849e-07 -> 5.36442e-07 diff=1.10e-06,1.10e-06 Linf=3.571e-07
#34: loss: 5.36442e-07 -> 5.06639e-07 diff=1.13e-06,1.13e-06 Linf=3.571e-07
#65: loss: 5.06639e-07 -> 4.76837e-07 diff=1.16e-06,1.16e-06 Linf=3.571e-07
#65: loss: 4.76837e-07 -> 4.17233e-07 diff=1.22e-06,1.22e-06 Linf=3.571e-07
#95: loss: 4.17233e-07 -> 3.57628e-07 diff=1.28e-06,1.28e-06 Linf=3.571e-07
#99: loss: 3.57628e-07 -> 3.27826e-07 diff=1.31e-06,1.31e-06 Linf=3.571e-07
#100: loss: 3.27826e-07 -> 1.78814e-07 diff=1.46e-06,1.46e-06 Linf=3.571e-07
#124: loss: 1.78814e-07 -> 1.49012e-07 diff=1.49e-06,1.49e-06 Linf=4.877e-07
#234: loss: 1.49012e-07 -> 1.19209e-07 diff=1.52e-06,1.52e-06 Linf=4.877e-07
#832: loss: 1.19209e-07 -> 5.96046e-08 diff=1.58e-06,1.58e-06 Linf=4.877e-07
working on output/mnist/6576.model with loss=1.66893e-06
#0: loss: 1.66893e-06 -> 1.43051e-06 diff=2.38e-07,2.38e-07 Linf=1.954e-07
#0: loss: 1.43051e-06 -> 1.31130e-06 diff=3.58e-07,3.58e-07 Linf=1.954e-07
#1: loss: 1.31130e-06 -> 1.07288e-06 diff=5.96e-07,5.96e-07 Linf=1.954e-07
#2: loss: 1.07288e-06 -> 8.34465e-07 diff=8.34e-07,8.34e-07 Linf=1.954e-07
#21: loss: 8.34465e-07 -> 5.96046e-07 diff=1.07e-06,1.07e-06 Linf=2.384e-07
#72: loss: 5.96046e-07 -> 3.57628e-07 diff=1.31e-06,1.31e-06 Linf=3.576e-07
#398: loss: 3.57628e-07 -> 1.19209e-07 diff=1.55e-06,1.55e-06 Linf=3.576e-07
#401: loss: 1.19209e-07 -> 0.00000e+00 diff=1.67e-06,1.67e-06 Linf=3.576e-07
#531: loss: 0.00000e+00 -> -1.19209e-07 diff=1.79e-06,1.79e-06 Linf=3.576e-07
conv [-5.41 -5.69 -5.06  1.56 -7.76  1.56 -4.08 -9.97 -0.96 -1.74] l=5 cw=2.86e-06
mm   [-5.41 -5.69 -5.06  1.56 -7.76  1.56 -4.08 -9.97 -0.96 -1.74] l=3 cw=-1.19e-07
test acc: 98.36%
verification of original model failed: {'ObjectiveBound': 0.021793551091345186,
 'ObjectiveValue': nan,
 'PredictedIndex': 6,
 'SolveStatus': 'UserLimit',
 'SolveTime': 360.0049240589142,
 'TargetIndexes': array([ 1,  2,  3,  4,  5,  7,  8,  9, 10]),
 'TighteningApproach': array([[108],
       [112]], dtype=uint16),
 'TotalTime': 372.229910063,
 'robust': False,
 'status_known': False}
working on output/mnist/850.model with loss=2.1457672e-06
#0: loss: 2.14577e-06 -> 2.02656e-06 diff=1.19e-07,1.19e-07 Linf=2.384e-07
#0: loss: 2.02656e-06 -> 1.90735e-06 diff=2.38e-07,2.38e-07 Linf=2.384e-07
#0: loss: 1.90735e-06 -> 1.78814e-06 diff=3.58e-07,3.58e-07 Linf=2.384e-07
#1: loss: 1.78814e-06 -> 1.66893e-06 diff=4.77e-07,4.77e-07 Linf=2.384e-07
#34: loss: 1.66893e-06 -> 1.54972e-06 diff=5.96e-07,5.96e-07 Linf=2.384e-07
#53: loss: 1.54972e-06 -> 1.43051e-06 diff=7.15e-07,7.15e-07 Linf=2.384e-07
#78: loss: 1.43051e-06 -> 1.31130e-06 diff=8.34e-07,8.34e-07 Linf=2.384e-07
working on output/mnist/6791.model with loss=2.1904707e-06
#0: loss: 2.19047e-06 -> 1.92225e-06 diff=2.68e-07,2.68e-07 Linf=2.384e-07
#0: loss: 1.92225e-06 -> 1.90735e-06 diff=2.83e-07,2.83e-07 Linf=2.384e-07
#1: loss: 1.90735e-06 -> 1.66893e-06 diff=5.22e-07,5.22e-07 Linf=3.129e-07
#1: loss: 1.66893e-06 -> 1.60933e-06 diff=5.81e-07,5.81e-07 Linf=3.129e-07
#1: loss: 1.60933e-06 -> 1.49012e-06 diff=7.00e-07,7.00e-07 Linf=3.129e-07
#8: loss: 1.49012e-06 -> 1.47521e-06 diff=7.15e-07,7.15e-07 Linf=3.568e-07
#14: loss: 1.47521e-06 -> 1.38581e-06 diff=8.05e-07,8.05e-07 Linf=3.568e-07
#14: loss: 1.38581e-06 -> 1.35601e-06 diff=8.34e-07,8.34e-07 Linf=3.568e-07
#53: loss: 1.35601e-06 -> 1.22190e-06 diff=9.69e-07,9.69e-07 Linf=3.568e-07
#54: loss: 1.22190e-06 -> 9.83477e-07 diff=1.21e-06,1.21e-06 Linf=3.568e-07
#55: loss: 9.83477e-07 -> 8.94070e-07 diff=1.30e-06,1.30e-06 Linf=3.568e-07
#147: loss: 8.94070e-07 -> 8.79169e-07 diff=1.31e-06,1.31e-06 Linf=3.568e-07
working on output/mnist/4798.model with loss=2.2649765e-06
#0: loss: 2.26498e-06 -> 1.37091e-06 diff=8.94e-07,8.94e-07 Linf=1.788e-07
#3: loss: 1.37091e-06 -> 1.13249e-06 diff=1.13e-06,1.13e-06 Linf=1.788e-07
#101: loss: 1.13249e-06 -> 1.01328e-06 diff=1.25e-06,1.25e-06 Linf=1.788e-07
#105: loss: 1.01328e-06 -> 7.74860e-07 diff=1.49e-06,1.49e-06 Linf=1.788e-07
#150: loss: 7.74860e-07 -> 6.55651e-07 diff=1.61e-06,1.61e-06 Linf=1.975e-07
#182: loss: 6.55651e-07 -> 5.96046e-07 diff=1.67e-06,1.67e-06 Linf=1.975e-07
#225: loss: 5.96046e-07 -> 5.36442e-07 diff=1.73e-06,1.73e-06 Linf=1.975e-07
working on output/mnist/2641.model with loss=2.2947788e-06
#0: loss: 2.29478e-06 -> 2.23517e-06 diff=5.96e-08,5.96e-08 Linf=2.086e-07
#2: loss: 2.23517e-06 -> 1.99676e-06 diff=2.98e-07,2.98e-07 Linf=2.086e-07
#2: loss: 1.99676e-06 -> 1.87755e-06 diff=4.17e-07,4.17e-07 Linf=2.086e-07
#5: loss: 1.87755e-06 -> 1.75834e-06 diff=5.36e-07,5.36e-07 Linf=2.086e-07
#19: loss: 1.75834e-06 -> 1.69873e-06 diff=5.96e-07,5.96e-07 Linf=2.820e-07
#24: loss: 1.69873e-06 -> 1.63913e-06 diff=6.56e-07,6.56e-07 Linf=2.820e-07
#25: loss: 1.63913e-06 -> 1.57952e-06 diff=7.15e-07,7.15e-07 Linf=2.820e-07
#28: loss: 1.57952e-06 -> 1.51992e-06 diff=7.75e-07,7.75e-07 Linf=2.820e-07
#30: loss: 1.51992e-06 -> 1.46031e-06 diff=8.34e-07,8.34e-07 Linf=2.820e-07
#32: loss: 1.46031e-06 -> 1.34110e-06 diff=9.54e-07,9.54e-07 Linf=2.820e-07
#36: loss: 1.34110e-06 -> 1.22190e-06 diff=1.07e-06,1.07e-06 Linf=2.820e-07
#40: loss: 1.22190e-06 -> 1.10269e-06 diff=1.19e-06,1.19e-06 Linf=2.820e-07
#177: loss: 1.10269e-06 -> 1.04308e-06 diff=1.25e-06,1.25e-06 Linf=2.820e-07
#199: loss: 1.04308e-06 -> 8.04663e-07 diff=1.49e-06,1.49e-06 Linf=2.820e-07
#223: loss: 8.04663e-07 -> 4.47035e-07 diff=1.85e-06,1.85e-06 Linf=2.980e-07
working on output/mnist/41.model with loss=2.3841858e-06
#0: loss: 2.38419e-06 -> 2.26498e-06 diff=1.19e-07,1.19e-07 Linf=1.490e-07
#0: loss: 2.26498e-06 -> 2.14577e-06 diff=2.38e-07,2.38e-07 Linf=1.647e-07
#0: loss: 2.14577e-06 -> 2.08616e-06 diff=2.98e-07,2.98e-07 Linf=1.647e-07
#0: loss: 2.08616e-06 -> 1.60933e-06 diff=7.75e-07,7.75e-07 Linf=1.985e-07
#1: loss: 1.60933e-06 -> 1.37091e-06 diff=1.01e-06,1.01e-06 Linf=1.985e-07
#2: loss: 1.37091e-06 -> 1.31130e-06 diff=1.07e-06,1.07e-06 Linf=1.985e-07
#10: loss: 1.31130e-06 -> 1.19209e-06 diff=1.19e-06,1.19e-06 Linf=1.985e-07
#11: loss: 1.19209e-06 -> 1.13249e-06 diff=1.25e-06,1.25e-06 Linf=1.985e-07
#11: loss: 1.13249e-06 -> 1.07288e-06 diff=1.31e-06,1.31e-06 Linf=2.461e-07
#12: loss: 1.07288e-06 -> 1.01328e-06 diff=1.37e-06,1.37e-06 Linf=2.932e-07
#14: loss: 1.01328e-06 -> 9.53674e-07 diff=1.43e-06,1.43e-06 Linf=2.932e-07
#52: loss: 9.53674e-07 -> 8.94070e-07 diff=1.49e-06,1.49e-06 Linf=2.932e-07
#55: loss: 8.94070e-07 -> 8.34465e-07 diff=1.55e-06,1.55e-06 Linf=2.932e-07
working on output/mnist/8571.model with loss=2.6226044e-06
#0: loss: 2.62260e-06 -> 1.66893e-06 diff=9.54e-07,9.54e-07 Linf=1.788e-07
#1: loss: 1.66893e-06 -> 1.19209e-06 diff=1.43e-06,1.43e-06 Linf=1.997e-07
#51: loss: 1.19209e-06 -> 7.15256e-07 diff=1.91e-06,1.91e-06 Linf=2.384e-07
#413: loss: 7.15256e-07 -> 2.38419e-07 diff=2.38e-06,2.38e-06 Linf=2.384e-07
working on output/mnist/2782.model with loss=3.0398369e-06
#0: loss: 3.03984e-06 -> 2.98023e-06 diff=5.96e-08,5.96e-08 Linf=1.937e-07
#0: loss: 2.98023e-06 -> 2.89083e-06 diff=1.49e-07,1.49e-07 Linf=1.937e-07
#0: loss: 2.89083e-06 -> 2.83122e-06 diff=2.09e-07,2.09e-07 Linf=1.937e-07
#0: loss: 2.83122e-06 -> 2.80142e-06 diff=2.38e-07,2.38e-07 Linf=2.086e-07
#1: loss: 2.80142e-06 -> 2.62260e-06 diff=4.17e-07,4.17e-07 Linf=2.086e-07
#1: loss: 2.62260e-06 -> 2.59280e-06 diff=4.47e-07,4.47e-07 Linf=2.086e-07
#27: loss: 2.59280e-06 -> 2.56300e-06 diff=4.77e-07,4.77e-07 Linf=2.086e-07
#28: loss: 2.56300e-06 -> 2.32458e-06 diff=7.15e-07,7.15e-07 Linf=2.086e-07
#30: loss: 2.32458e-06 -> 2.29478e-06 diff=7.45e-07,7.45e-07 Linf=2.715e-07
#55: loss: 2.29478e-06 -> 2.23517e-06 diff=8.05e-07,8.05e-07 Linf=2.715e-07
#62: loss: 2.23517e-06 -> 2.17557e-06 diff=8.64e-07,8.64e-07 Linf=2.715e-07
#63: loss: 2.17557e-06 -> 2.11596e-06 diff=9.24e-07,9.24e-07 Linf=2.715e-07
#110: loss: 2.11596e-06 -> 1.99676e-06 diff=1.04e-06,1.04e-06 Linf=2.715e-07
working on output/mnist/1459.model with loss=3.1590462e-06
#0: loss: 3.15905e-06 -> 2.92063e-06 diff=2.38e-07,2.38e-07 Linf=2.384e-07
#0: loss: 2.92063e-06 -> 2.50340e-06 diff=6.56e-07,6.56e-07 Linf=2.384e-07
#1: loss: 2.50340e-06 -> 2.38419e-06 diff=7.75e-07,7.75e-07 Linf=2.384e-07
#2: loss: 2.38419e-06 -> 2.26498e-06 diff=8.94e-07,8.94e-07 Linf=2.384e-07
#38: loss: 2.26498e-06 -> 2.14577e-06 diff=1.01e-06,1.01e-06 Linf=2.384e-07
#39: loss: 2.14577e-06 -> 2.02656e-06 diff=1.13e-06,1.13e-06 Linf=2.384e-07
#62: loss: 2.02656e-06 -> 1.90735e-06 diff=1.25e-06,1.25e-06 Linf=2.980e-07
#67: loss: 1.90735e-06 -> 1.78814e-06 diff=1.37e-06,1.37e-06 Linf=2.980e-07
#68: loss: 1.78814e-06 -> 1.66893e-06 diff=1.49e-06,1.49e-06 Linf=2.980e-07
#224: loss: 1.66893e-06 -> 1.54972e-06 diff=1.61e-06,1.61e-06 Linf=2.980e-07
#255: loss: 1.54972e-06 -> 1.43051e-06 diff=1.73e-06,1.73e-06 Linf=2.980e-07
#489: loss: 1.43051e-06 -> 1.31130e-06 diff=1.85e-06,1.85e-06 Linf=3.576e-07
#623: loss: 1.31130e-06 -> 1.19209e-06 diff=1.97e-06,1.97e-06 Linf=4.470e-07
working on output/mnist/9285.model with loss=3.2186508e-06
#0: loss: 3.21865e-06 -> 2.62260e-06 diff=5.96e-07,5.96e-07 Linf=1.863e-07
#0: loss: 2.62260e-06 -> 2.38419e-06 diff=8.34e-07,8.34e-07 Linf=2.086e-07
#0: loss: 2.38419e-06 -> 2.26498e-06 diff=9.54e-07,9.54e-07 Linf=2.086e-07
#2: loss: 2.26498e-06 -> 2.14577e-06 diff=1.07e-06,1.07e-06 Linf=2.086e-07
#31: loss: 2.14577e-06 -> 2.02656e-06 diff=1.19e-06,1.19e-06 Linf=2.086e-07
#32: loss: 2.02656e-06 -> 1.78814e-06 diff=1.43e-06,1.43e-06 Linf=2.086e-07
#33: loss: 1.78814e-06 -> 1.54972e-06 diff=1.67e-06,1.67e-06 Linf=2.086e-07
#96: loss: 1.54972e-06 -> 1.31130e-06 diff=1.91e-06,1.91e-06 Linf=2.682e-07
working on output/mnist/1461.model with loss=3.993511e-06
#0: loss: 3.99351e-06 -> 3.69549e-06 diff=2.98e-07,2.98e-07 Linf=1.853e-07
#0: loss: 3.69549e-06 -> 3.57628e-06 diff=4.17e-07,4.17e-07 Linf=2.086e-07
#1: loss: 3.57628e-06 -> 3.45707e-06 diff=5.36e-07,5.36e-07 Linf=2.086e-07
#2: loss: 3.45707e-06 -> 2.86102e-06 diff=1.13e-06,1.13e-06 Linf=2.086e-07
#30: loss: 2.86102e-06 -> 2.74181e-06 diff=1.25e-06,1.25e-06 Linf=3.120e-07
#47: loss: 2.74181e-06 -> 2.68221e-06 diff=1.31e-06,1.31e-06 Linf=3.120e-07
#57: loss: 2.68221e-06 -> 2.62260e-06 diff=1.37e-06,1.37e-06 Linf=3.120e-07
#75: loss: 2.62260e-06 -> 2.56300e-06 diff=1.43e-06,1.43e-06 Linf=3.120e-07
#93: loss: 2.56300e-06 -> 2.50340e-06 diff=1.49e-06,1.49e-06 Linf=3.120e-07
#150: loss: 2.50340e-06 -> 2.44379e-06 diff=1.55e-06,1.55e-06 Linf=3.431e-07
#712: loss: 2.44379e-06 -> 2.38419e-06 diff=1.61e-06,1.61e-06 Linf=4.891e-07
working on output/mnist/1212.model with loss=4.4107437e-06
#0: loss: 4.41074e-06 -> 3.69549e-06 diff=7.15e-07,7.15e-07 Linf=2.384e-07
#0: loss: 3.69549e-06 -> 3.57628e-06 diff=8.34e-07,8.34e-07 Linf=2.384e-07
#1: loss: 3.57628e-06 -> 3.33786e-06 diff=1.07e-06,1.07e-06 Linf=2.384e-07
#1: loss: 3.33786e-06 -> 3.09944e-06 diff=1.31e-06,1.31e-06 Linf=2.384e-07
#7: loss: 3.09944e-06 -> 3.03984e-06 diff=1.37e-06,1.37e-06 Linf=2.384e-07
#10: loss: 3.03984e-06 -> 2.80142e-06 diff=1.61e-06,1.61e-06 Linf=2.384e-07
#18: loss: 2.80142e-06 -> 2.68221e-06 diff=1.73e-06,1.73e-06 Linf=2.384e-07
#318: loss: 2.68221e-06 -> 2.56300e-06 diff=1.85e-06,1.85e-06 Linf=2.384e-07
#548: loss: 2.56300e-06 -> 2.50340e-06 diff=1.91e-06,1.91e-06 Linf=2.384e-07
#555: loss: 2.50340e-06 -> 2.44379e-06 diff=1.97e-06,1.97e-06 Linf=2.384e-07
