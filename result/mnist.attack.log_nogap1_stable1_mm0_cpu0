preprocessing on output/mnist/1212.model
adv_loss=1.5184226036071777 adv_loss_mm=1.51842200756073 inp_loss=5.792226791381836 gap=0
preprocessing on output/mnist/1459.model
adv_loss=1.0982179641723633 adv_loss_mm=1.0982179641723633 inp_loss=5.227838516235352 gap=0
preprocessing on output/mnist/1461.model
adv_loss=2.0746445655822754 adv_loss_mm=2.0746452808380127 inp_loss=5.423094749450684 gap=0
preprocessing on output/mnist/2641.model
adv_loss=2.2001752853393555 adv_loss_mm=2.200176239013672 inp_loss=5.337521076202393 gap=0
preprocessing on output/mnist/2782.model
adv_loss=0.039579808712005615 adv_loss_mm=0.03957867622375488 inp_loss=3.4935989379882812 gap=0
preprocessing on output/mnist/3860.model
adv_loss=3.6739730834960938 adv_loss_mm=3.673973560333252 inp_loss=7.539007186889648 gap=0
preprocessing on output/mnist/3966.model
adv_loss=1.7583370208740234e-06 adv_loss_mm=1.6987323760986328e-06 inp_loss=2.7201290130615234 gap=0
preprocessing on output/mnist/41.model
adv_loss=2.205371856689453e-06 adv_loss_mm=2.562999725341797e-06 inp_loss=2.527251720428467 gap=0
preprocessing on output/mnist/4798.model
adv_loss=0.8083765506744385 adv_loss_mm=0.8083771467208862 inp_loss=4.010872840881348 gap=0
preprocessing on output/mnist/6327.model
adv_loss=1.8775463104248047e-06 adv_loss_mm=1.7583370208740234e-06 inp_loss=3.296889543533325 gap=0
preprocessing on output/mnist/6576.model
adv_loss=1.6094632148742676 adv_loss_mm=1.6094621419906616 inp_loss=4.571714401245117 gap=0
preprocessing on output/mnist/6791.model
adv_loss=0.09270855784416199 adv_loss_mm=0.0927092432975769 inp_loss=3.9481217861175537 gap=0
preprocessing on output/mnist/6929.model
adv_loss=1.8453514575958252 adv_loss_mm=1.8453518152236938 inp_loss=6.63316535949707 gap=0
preprocessing on output/mnist/7186.model
adv_loss=1.3113021850585938e-06 adv_loss_mm=2.384185791015625e-06 inp_loss=3.5544919967651367 gap=0
preprocessing on output/mnist/850.model
adv_loss=4.291534423828125e-06 adv_loss_mm=4.76837158203125e-06 inp_loss=3.725203514099121 gap=0
preprocessing on output/mnist/8571.model
adv_loss=4.291534423828125e-06 adv_loss_mm=3.337860107421875e-06 inp_loss=3.5111234188079834 gap=0
preprocessing on output/mnist/890.model
adv_loss=9.5367431640625e-07 adv_loss_mm=1.6689300537109375e-06 inp_loss=2.5032894611358643 gap=0
preprocessing on output/mnist/9285.model
adv_loss=0.4836263656616211 adv_loss_mm=0.48362767696380615 inp_loss=3.4556708335876465 gap=0
working on output/mnist/890.model with loss=9.536743e-07
#0: loss: 9.53674e-07 -> 7.15256e-07 diff=2.38e-07,9.54e-07 Linf=1.788e-07
#2: loss: 7.15256e-07 -> 2.38419e-07 diff=7.15e-07,1.43e-06 Linf=3.576e-07
#28: loss: 2.38419e-07 -> 1.19209e-07 diff=8.34e-07,1.55e-06 Linf=3.576e-07
#70: loss: 1.19209e-07 -> 0.00000e+00 diff=9.54e-07,1.67e-06 Linf=3.576e-07
#71: loss: 0.00000e+00 -> -2.38419e-07 diff=1.19e-06,1.91e-06 Linf=3.576e-07
conv [-4.98 -7.59  0.75 -1.23 -7.24 -9.37 -8.33  0.75 -2.24 -2.19] l=2 cw=-2.38e-07
mm   [-4.98 -7.59  0.75 -1.23 -7.24 -9.37 -8.33  0.75 -2.24 -2.19] l=7 cw=1.43e-06
test acc: 98.57%
working on output/mnist/7186.model with loss=1.3113022e-06
#0: loss: 1.31130e-06 -> 1.07288e-06 diff=2.38e-07,1.31e-06 Linf=1.714e-07
#1: loss: 1.07288e-06 -> 9.53674e-07 diff=3.58e-07,1.43e-06 Linf=1.714e-07
#3: loss: 9.53674e-07 -> 8.34465e-07 diff=4.77e-07,1.55e-06 Linf=1.714e-07
#54: loss: 8.34465e-07 -> 5.96046e-07 diff=7.15e-07,1.79e-06 Linf=1.788e-07
#54: loss: 5.96046e-07 -> 3.57628e-07 diff=9.54e-07,2.03e-06 Linf=1.812e-07
#56: loss: 3.57628e-07 -> 1.19209e-07 diff=1.19e-06,2.26e-06 Linf=1.832e-07
#152: loss: 1.19209e-07 -> -1.19209e-07 diff=1.43e-06,2.50e-06 Linf=2.459e-07
conv [-8.2  -1.35 -5.06 -2.56 -4.39 -1.35 -5.48 -5.48 -2.65 -3.  ] l=5 cw=-1.19e-07
mm   [-8.2  -1.35 -5.06 -2.56 -4.39 -1.35 -5.48 -5.48 -2.65 -3.  ] l=1 cw=2.62e-06
test acc: 98.57%
working on output/mnist/3966.model with loss=1.758337e-06
#0: loss: 1.75834e-06 -> 1.63913e-06 diff=1.19e-07,5.96e-08 Linf=1.937e-07
#0: loss: 1.63913e-06 -> 1.43051e-06 diff=3.28e-07,2.68e-07 Linf=2.086e-07
#2: loss: 1.43051e-06 -> 1.22190e-06 diff=5.36e-07,4.77e-07 Linf=2.086e-07
#3: loss: 1.22190e-06 -> 1.10269e-06 diff=6.56e-07,5.96e-07 Linf=2.086e-07
#3: loss: 1.10269e-06 -> 1.04308e-06 diff=7.15e-07,6.56e-07 Linf=2.384e-07
#9: loss: 1.04308e-06 -> 9.53674e-07 diff=8.05e-07,7.45e-07 Linf=2.384e-07
#27: loss: 9.53674e-07 -> 8.34465e-07 diff=9.24e-07,8.64e-07 Linf=2.773e-07
#37: loss: 8.34465e-07 -> 8.04663e-07 diff=9.54e-07,8.94e-07 Linf=2.773e-07
#47: loss: 8.04663e-07 -> 7.45058e-07 diff=1.01e-06,9.54e-07 Linf=2.773e-07
working on output/mnist/6327.model with loss=1.8775463e-06
#0: loss: 1.87755e-06 -> 1.63913e-06 diff=2.38e-07,1.19e-07 Linf=1.737e-07
#0: loss: 1.63913e-06 -> 1.51992e-06 diff=3.58e-07,2.38e-07 Linf=2.384e-07
#0: loss: 1.51992e-06 -> 1.22190e-06 diff=6.56e-07,5.36e-07 Linf=2.384e-07
#1: loss: 1.22190e-06 -> 1.16229e-06 diff=7.15e-07,5.96e-07 Linf=2.384e-07
#1: loss: 1.16229e-06 -> 7.45058e-07 diff=1.13e-06,1.01e-06 Linf=2.384e-07
#2: loss: 7.45058e-07 -> 6.85453e-07 diff=1.19e-06,1.07e-06 Linf=2.384e-07
#5: loss: 6.85453e-07 -> 6.25849e-07 diff=1.25e-06,1.13e-06 Linf=2.384e-07
#26: loss: 6.25849e-07 -> 5.06639e-07 diff=1.37e-06,1.25e-06 Linf=2.384e-07
#27: loss: 5.06639e-07 -> 2.68221e-07 diff=1.61e-06,1.49e-06 Linf=2.595e-07
#27: loss: 2.68221e-07 -> 2.08616e-07 diff=1.67e-06,1.55e-06 Linf=2.595e-07
#29: loss: 2.08616e-07 -> 8.94070e-08 diff=1.79e-06,1.67e-06 Linf=2.757e-07
#42: loss: 8.94070e-08 -> -2.98023e-08 diff=1.91e-06,1.79e-06 Linf=2.757e-07
#47: loss: -2.98023e-08 -> -3.27826e-07 diff=2.21e-06,2.09e-06 Linf=3.651e-07
conv [-3.97 -4.93 -4.93 -4.77 -5.1  -0.31 -2.56 -7.34 -0.31 -5.6 ] l=5 cw=-3.28e-07
mm   [-3.97 -4.93 -4.93 -4.77 -5.1  -0.31 -2.56 -7.34 -0.31 -5.6 ] l=8 cw=2.71e-06
test acc: 98.57%
working on output/mnist/41.model with loss=2.2053719e-06
#0: loss: 2.20537e-06 -> 2.14577e-06 diff=5.96e-08,4.17e-07 Linf=1.267e-07
#1: loss: 2.14577e-06 -> 2.08616e-06 diff=1.19e-07,4.77e-07 Linf=1.788e-07
#27: loss: 2.08616e-06 -> 2.02656e-06 diff=1.79e-07,5.36e-07 Linf=1.788e-07
#29: loss: 2.02656e-06 -> 1.78814e-06 diff=4.17e-07,7.75e-07 Linf=1.788e-07
#32: loss: 1.78814e-06 -> 1.37091e-06 diff=8.34e-07,1.19e-06 Linf=3.725e-07
#33: loss: 1.37091e-06 -> 1.31130e-06 diff=8.94e-07,1.25e-06 Linf=3.725e-07
#33: loss: 1.31130e-06 -> 1.13249e-06 diff=1.07e-06,1.43e-06 Linf=3.725e-07
#560: loss: 1.13249e-06 -> 1.07288e-06 diff=1.13e-06,1.49e-06 Linf=3.725e-07
#561: loss: 1.07288e-06 -> 1.01328e-06 diff=1.19e-06,1.55e-06 Linf=3.725e-07
#569: loss: 1.01328e-06 -> 9.53674e-07 diff=1.25e-06,1.61e-06 Linf=3.725e-07
working on output/mnist/850.model with loss=4.2915344e-06
#0: loss: 4.29153e-06 -> 4.05312e-06 diff=2.38e-07,7.15e-07 Linf=1.937e-07
#2: loss: 4.05312e-06 -> 3.93391e-06 diff=3.58e-07,8.34e-07 Linf=1.937e-07
#5: loss: 3.93391e-06 -> 3.81470e-06 diff=4.77e-07,9.54e-07 Linf=1.937e-07
#49: loss: 3.81470e-06 -> 3.57628e-06 diff=7.15e-07,1.19e-06 Linf=1.997e-07
#126: loss: 3.57628e-06 -> 3.45707e-06 diff=8.34e-07,1.31e-06 Linf=1.997e-07
#142: loss: 3.45707e-06 -> 3.33786e-06 diff=9.54e-07,1.43e-06 Linf=1.997e-07
#217: loss: 3.33786e-06 -> 3.21865e-06 diff=1.07e-06,1.55e-06 Linf=2.012e-07
#223: loss: 3.21865e-06 -> 3.09944e-06 diff=1.19e-06,1.67e-06 Linf=2.012e-07
#464: loss: 3.09944e-06 -> 2.98023e-06 diff=1.31e-06,1.79e-06 Linf=2.012e-07
working on output/mnist/8571.model with loss=4.2915344e-06
#0: loss: 4.29153e-06 -> 3.57628e-06 diff=7.15e-07,-2.38e-07 Linf=1.809e-07
#0: loss: 3.57628e-06 -> 3.09944e-06 diff=1.19e-06,2.38e-07 Linf=1.937e-07
#1: loss: 3.09944e-06 -> 2.62260e-06 diff=1.67e-06,7.15e-07 Linf=1.968e-07
#1: loss: 2.62260e-06 -> 2.38419e-06 diff=1.91e-06,9.54e-07 Linf=1.968e-07
#1: loss: 2.38419e-06 -> 2.14577e-06 diff=2.15e-06,1.19e-06 Linf=3.502e-07
#631: loss: 2.14577e-06 -> 1.90735e-06 diff=2.38e-06,1.43e-06 Linf=3.502e-07
working on output/mnist/2782.model with loss=0.03957981
#0: loss: 3.95798e-02 -> 3.95790e-02 diff=8.34e-07,-2.98e-07 Linf=1.937e-07
#0: loss: 3.95790e-02 -> 3.95787e-02 diff=1.07e-06,-5.96e-08 Linf=1.979e-07
#7: loss: 3.95787e-02 -> 3.95787e-02 diff=1.10e-06,-2.98e-08 Linf=1.979e-07
#8: loss: 3.95787e-02 -> 3.95786e-02 diff=1.16e-06,2.98e-08 Linf=1.979e-07
#11: loss: 3.95786e-02 -> 3.95785e-02 diff=1.28e-06,1.49e-07 Linf=1.979e-07
#14: loss: 3.95785e-02 -> 3.95783e-02 diff=1.52e-06,3.87e-07 Linf=2.012e-07
#18: loss: 3.95783e-02 -> 3.95782e-02 diff=1.58e-06,4.47e-07 Linf=3.186e-07
#22: loss: 3.95782e-02 -> 3.95782e-02 diff=1.64e-06,5.07e-07 Linf=3.186e-07
#59: loss: 3.95782e-02 -> 3.95781e-02 diff=1.67e-06,5.36e-07 Linf=3.743e-07
#59: loss: 3.95781e-02 -> 3.95781e-02 diff=1.70e-06,5.66e-07 Linf=3.743e-07
#62: loss: 3.95781e-02 -> 3.95780e-02 diff=1.82e-06,6.85e-07 Linf=3.743e-07
#74: loss: 3.95780e-02 -> 3.95779e-02 diff=1.94e-06,8.05e-07 Linf=3.743e-07
#112: loss: 3.95779e-02 -> 3.95778e-02 diff=2.00e-06,8.64e-07 Linf=3.743e-07
#229: loss: 3.95778e-02 -> 3.95778e-02 diff=2.06e-06,9.24e-07 Linf=3.743e-07
#446: loss: 3.95778e-02 -> 3.95776e-02 diff=2.18e-06,1.04e-06 Linf=3.743e-07
#453: loss: 3.95776e-02 -> 3.95776e-02 diff=2.24e-06,1.10e-06 Linf=3.743e-07
#708: loss: 3.95776e-02 -> 3.95775e-02 diff=2.26e-06,1.13e-06 Linf=3.743e-07
#800: loss: 3.95775e-02 -> 3.95775e-02 diff=2.35e-06,1.22e-06 Linf=4.789e-07
#802: loss: 3.95775e-02 -> 3.95774e-02 diff=2.41e-06,1.28e-06 Linf=4.789e-07
#809: loss: 3.95774e-02 -> 3.95773e-02 diff=2.47e-06,1.34e-06 Linf=4.789e-07
#824: loss: 3.95773e-02 -> 3.95773e-02 diff=2.53e-06,1.40e-06 Linf=4.789e-07
working on output/mnist/6791.model with loss=0.09270856
#0: loss: 9.27086e-02 -> 9.27084e-02 diff=1.49e-07,8.34e-07 Linf=1.386e-07
#1: loss: 9.27084e-02 -> 9.27082e-02 diff=3.28e-07,1.01e-06 Linf=1.909e-07
#1: loss: 9.27082e-02 -> 9.27082e-02 diff=3.58e-07,1.04e-06 Linf=2.384e-07
#1: loss: 9.27082e-02 -> 9.27081e-02 diff=5.07e-07,1.19e-06 Linf=2.384e-07
#2: loss: 9.27081e-02 -> 9.27080e-02 diff=5.36e-07,1.22e-06 Linf=2.384e-07
#18: loss: 9.27080e-02 -> 9.27080e-02 diff=5.96e-07,1.28e-06 Linf=2.384e-07
#23: loss: 9.27080e-02 -> 9.27079e-02 diff=6.56e-07,1.34e-06 Linf=2.384e-07
#23: loss: 9.27079e-02 -> 9.27078e-02 diff=7.15e-07,1.40e-06 Linf=2.384e-07
#34: loss: 9.27078e-02 -> 9.27078e-02 diff=7.75e-07,1.46e-06 Linf=2.384e-07
#66: loss: 9.27078e-02 -> 9.27076e-02 diff=9.54e-07,1.64e-06 Linf=2.384e-07
#70: loss: 9.27076e-02 -> 9.27075e-02 diff=1.10e-06,1.79e-06 Linf=2.384e-07
working on output/mnist/9285.model with loss=0.48362637
#1: loss: 4.83626e-01 -> 4.83626e-01 diff=1.19e-07,1.43e-06 Linf=1.937e-07
#2: loss: 4.83626e-01 -> 4.83626e-01 diff=5.96e-07,1.91e-06 Linf=1.937e-07
#2: loss: 4.83626e-01 -> 4.83626e-01 diff=7.15e-07,2.03e-06 Linf=1.937e-07
#11: loss: 4.83626e-01 -> 4.83626e-01 diff=8.34e-07,2.15e-06 Linf=1.937e-07
#17: loss: 4.83626e-01 -> 4.83625e-01 diff=9.54e-07,2.26e-06 Linf=1.937e-07
working on output/mnist/4798.model with loss=0.80837655
#0: loss: 8.08377e-01 -> 8.08376e-01 diff=1.19e-07,7.15e-07 Linf=1.977e-07
#5: loss: 8.08376e-01 -> 8.08376e-01 diff=2.38e-07,8.34e-07 Linf=1.977e-07
#26: loss: 8.08376e-01 -> 8.08376e-01 diff=3.58e-07,9.54e-07 Linf=1.977e-07
#353: loss: 8.08376e-01 -> 8.08376e-01 diff=4.77e-07,1.07e-06 Linf=1.977e-07
#681: loss: 8.08376e-01 -> 8.08376e-01 diff=6.56e-07,1.25e-06 Linf=1.977e-07
#723: loss: 8.08376e-01 -> 8.08376e-01 diff=8.34e-07,1.43e-06 Linf=1.977e-07
#983: loss: 8.08376e-01 -> 8.08376e-01 diff=9.54e-07,1.55e-06 Linf=1.977e-07
working on output/mnist/1459.model with loss=1.098218
#0: loss: 1.09822e+00 -> 1.09822e+00 diff=2.38e-07,2.38e-07 Linf=1.908e-07
#0: loss: 1.09822e+00 -> 1.09822e+00 diff=4.77e-07,4.77e-07 Linf=2.384e-07
#0: loss: 1.09822e+00 -> 1.09822e+00 diff=7.15e-07,7.15e-07 Linf=2.384e-07
#4: loss: 1.09822e+00 -> 1.09822e+00 diff=8.34e-07,8.34e-07 Linf=2.384e-07
#14: loss: 1.09822e+00 -> 1.09822e+00 diff=9.54e-07,9.54e-07 Linf=2.384e-07
#15: loss: 1.09822e+00 -> 1.09822e+00 diff=1.19e-06,1.19e-06 Linf=1.968e-07
working on output/mnist/1212.model with loss=1.5184226
#0: loss: 1.51842e+00 -> 1.51842e+00 diff=2.38e-07,-3.58e-07 Linf=1.868e-07
#0: loss: 1.51842e+00 -> 1.51842e+00 diff=9.54e-07,3.58e-07 Linf=2.384e-07
#1: loss: 1.51842e+00 -> 1.51842e+00 diff=1.19e-06,5.96e-07 Linf=2.384e-07
#7: loss: 1.51842e+00 -> 1.51842e+00 diff=1.43e-06,8.34e-07 Linf=2.384e-07
#326: loss: 1.51842e+00 -> 1.51842e+00 diff=1.67e-06,1.07e-06 Linf=2.384e-07
#353: loss: 1.51842e+00 -> 1.51842e+00 diff=1.91e-06,1.31e-06 Linf=2.384e-07
working on output/mnist/6576.model with loss=1.6094632
#0: loss: 1.60946e+00 -> 1.60946e+00 diff=2.38e-07,-8.34e-07 Linf=1.192e-07
#0: loss: 1.60946e+00 -> 1.60946e+00 diff=4.77e-07,-5.96e-07 Linf=1.875e-07
#0: loss: 1.60946e+00 -> 1.60946e+00 diff=7.15e-07,-3.58e-07 Linf=1.999e-07
#1: loss: 1.60946e+00 -> 1.60946e+00 diff=9.54e-07,-1.19e-07 Linf=1.999e-07
#2: loss: 1.60946e+00 -> 1.60946e+00 diff=1.19e-06,1.19e-07 Linf=1.999e-07
#9: loss: 1.60946e+00 -> 1.60946e+00 diff=1.31e-06,2.38e-07 Linf=1.999e-07
#20: loss: 1.60946e+00 -> 1.60946e+00 diff=1.43e-06,3.58e-07 Linf=2.086e-07
#20: loss: 1.60946e+00 -> 1.60946e+00 diff=1.55e-06,4.77e-07 Linf=2.086e-07
#25: loss: 1.60946e+00 -> 1.60946e+00 diff=1.67e-06,5.96e-07 Linf=2.086e-07
#87: loss: 1.60946e+00 -> 1.60946e+00 diff=1.79e-06,7.15e-07 Linf=2.086e-07
#87: loss: 1.60946e+00 -> 1.60946e+00 diff=1.91e-06,8.34e-07 Linf=3.278e-07
#89: loss: 1.60946e+00 -> 1.60946e+00 diff=2.15e-06,1.07e-06 Linf=3.687e-07
working on output/mnist/6929.model with loss=1.8453515
#0: loss: 1.84535e+00 -> 1.84535e+00 diff=2.38e-07,5.96e-07 Linf=1.565e-07
#1: loss: 1.84535e+00 -> 1.84535e+00 diff=5.96e-07,9.54e-07 Linf=1.788e-07
#2: loss: 1.84535e+00 -> 1.84535e+00 diff=7.15e-07,1.07e-06 Linf=1.788e-07
#21: loss: 1.84535e+00 -> 1.84535e+00 diff=9.54e-07,1.31e-06 Linf=1.788e-07
#103: loss: 1.84535e+00 -> 1.84535e+00 diff=1.19e-06,1.55e-06 Linf=1.788e-07
#114: loss: 1.84535e+00 -> 1.84535e+00 diff=1.31e-06,1.67e-06 Linf=1.788e-07
#184: loss: 1.84535e+00 -> 1.84535e+00 diff=1.43e-06,1.79e-06 Linf=3.056e-07
#196: loss: 1.84535e+00 -> 1.84535e+00 diff=1.55e-06,1.91e-06 Linf=3.056e-07
#688: loss: 1.84535e+00 -> 1.84535e+00 diff=1.67e-06,2.03e-06 Linf=3.056e-07
working on output/mnist/1461.model with loss=2.0746446
#3: loss: 2.07464e+00 -> 2.07464e+00 diff=2.38e-07,9.54e-07 Linf=2.384e-07
#4: loss: 2.07464e+00 -> 2.07464e+00 diff=4.77e-07,1.19e-06 Linf=2.384e-07
#42: loss: 2.07464e+00 -> 2.07464e+00 diff=7.15e-07,1.43e-06 Linf=2.384e-07
#256: loss: 2.07464e+00 -> 2.07464e+00 diff=9.54e-07,1.67e-06 Linf=2.384e-07
working on output/mnist/2641.model with loss=2.2001753
#0: loss: 2.20018e+00 -> 2.20018e+00 diff=2.38e-07,1.19e-06 Linf=2.384e-07
#0: loss: 2.20018e+00 -> 2.20017e+00 diff=4.77e-07,1.43e-06 Linf=2.384e-07
#0: loss: 2.20017e+00 -> 2.20017e+00 diff=7.15e-07,1.67e-06 Linf=2.384e-07
#325: loss: 2.20017e+00 -> 2.20017e+00 diff=9.54e-07,1.91e-06 Linf=3.129e-07
working on output/mnist/3860.model with loss=3.673973
#0: loss: 3.67397e+00 -> 3.67397e+00 diff=4.77e-07,9.54e-07 Linf=1.565e-07
#0: loss: 3.67397e+00 -> 3.67397e+00 diff=7.15e-07,1.19e-06 Linf=1.565e-07
#1: loss: 3.67397e+00 -> 3.67397e+00 diff=9.54e-07,1.43e-06 Linf=1.788e-07
#4: loss: 3.67397e+00 -> 3.67397e+00 diff=1.19e-06,1.67e-06 Linf=1.788e-07
