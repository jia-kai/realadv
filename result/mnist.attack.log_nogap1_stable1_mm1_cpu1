preprocessing on output/mnist/1212.model
adv_loss=1.5184223651885986 adv_loss_mm=1.5184223651885986 inp_loss=5.792226314544678 gap=0
preprocessing on output/mnist/1459.model
adv_loss=1.0982162952423096 adv_loss_mm=1.098217487335205 inp_loss=5.227838516235352 gap=0
preprocessing on output/mnist/1461.model
adv_loss=2.07464599609375 adv_loss_mm=2.0746448040008545 inp_loss=5.423095226287842 gap=0
preprocessing on output/mnist/2641.model
adv_loss=2.2001760005950928 adv_loss_mm=2.2001748085021973 inp_loss=5.337521076202393 gap=0
preprocessing on output/mnist/2782.model
adv_loss=0.0395791232585907 adv_loss_mm=0.039580196142196655 inp_loss=3.4935965538024902 gap=0
preprocessing on output/mnist/3860.model
adv_loss=3.67397403717041 adv_loss_mm=3.6739754676818848 inp_loss=7.53900671005249 gap=0
preprocessing on output/mnist/3966.model
adv_loss=4.76837158203125e-07 adv_loss_mm=9.5367431640625e-07 inp_loss=2.7201309204101562 gap=0
preprocessing on output/mnist/41.model
adv_loss=1.7881393432617188e-06 adv_loss_mm=3.337860107421875e-06 inp_loss=2.527252674102783 gap=0
preprocessing on output/mnist/4798.model
adv_loss=0.8083769083023071 adv_loss_mm=0.8083765506744385 inp_loss=4.010873794555664 gap=0
preprocessing on output/mnist/6327.model
adv_loss=2.2351741790771484e-06 adv_loss_mm=1.2814998626708984e-06 inp_loss=3.296889543533325 gap=0
preprocessing on output/mnist/6576.model
adv_loss=1.609461784362793 adv_loss_mm=1.6094629764556885 inp_loss=4.571714878082275 gap=0
preprocessing on output/mnist/6791.model
adv_loss=0.09270972013473511 adv_loss_mm=0.09271001815795898 inp_loss=3.948122501373291 gap=0
preprocessing on output/mnist/6929.model
adv_loss=1.8453528881072998 adv_loss_mm=1.8453514575958252 inp_loss=6.633164405822754 gap=0
preprocessing on output/mnist/7186.model
adv_loss=4.172325134277344e-06 adv_loss_mm=3.0994415283203125e-06 inp_loss=3.554490804672241 gap=0
preprocessing on output/mnist/850.model
adv_loss=4.887580871582031e-06 adv_loss_mm=3.4570693969726562e-06 inp_loss=3.7252025604248047 gap=0
preprocessing on output/mnist/8571.model
adv_loss=2.1457672119140625e-06 adv_loss_mm=3.0994415283203125e-06 inp_loss=3.5111231803894043 gap=0
preprocessing on output/mnist/890.model
adv_loss=1.5497207641601562e-06 adv_loss_mm=1.6689300537109375e-06 inp_loss=2.5032901763916016 gap=0
preprocessing on output/mnist/9285.model
adv_loss=0.4836256504058838 adv_loss_mm=0.4836268424987793 inp_loss=3.4556725025177 gap=0
working on output/mnist/3966.model with loss=9.536743e-07
#0: loss: 9.53674e-07 -> 3.57628e-07 diff=5.96e-07,5.96e-07 Linf=1.863e-07
#0: loss: 3.57628e-07 -> 2.38419e-07 diff=7.15e-07,7.15e-07 Linf=1.866e-07
#1: loss: 2.38419e-07 -> 1.19209e-07 diff=8.34e-07,8.34e-07 Linf=1.882e-07
#4: loss: 1.19209e-07 -> 0.00000e+00 diff=9.54e-07,9.54e-07 Linf=2.012e-07
#4: loss: 0.00000e+00 -> -2.38419e-07 diff=1.19e-06,1.19e-06 Linf=2.012e-07
#11: loss: -2.38419e-07 -> -3.57628e-07 diff=1.31e-06,1.31e-06 Linf=3.666e-07
#12: loss: -3.57628e-07 -> -7.15256e-07 diff=1.67e-06,1.67e-06 Linf=3.666e-07
#32: loss: -7.15256e-07 -> -9.53674e-07 diff=1.91e-06,1.91e-06 Linf=3.666e-07
#115: loss: -9.53674e-07 -> -1.19209e-06 diff=2.15e-06,2.15e-06 Linf=3.666e-07
conv [-9.52 -4.02 -5.99 -3.45 -0.2  -5.1  -8.7  -3.2  -2.61 -0.2 ] l=9 cw=1.31e-06
mm   [-9.52 -4.02 -5.99 -3.45 -0.2  -5.1  -8.7  -3.2  -2.61 -0.2 ] l=4 cw=-1.19e-06
test acc: 98.57%
working on output/mnist/6327.model with loss=1.2814999e-06
#0: loss: 1.28150e-06 -> 1.04308e-06 diff=2.38e-07,2.38e-07 Linf=2.384e-07
#1: loss: 1.04308e-06 -> 8.04663e-07 diff=4.77e-07,4.77e-07 Linf=2.384e-07
#6: loss: 8.04663e-07 -> 5.66244e-07 diff=7.15e-07,7.15e-07 Linf=2.384e-07
#44: loss: 5.66244e-07 -> 3.27826e-07 diff=9.54e-07,9.54e-07 Linf=2.384e-07
#44: loss: 3.27826e-07 -> 8.94070e-08 diff=1.19e-06,1.19e-06 Linf=2.384e-07
working on output/mnist/890.model with loss=1.66893e-06
#0: loss: 1.66893e-06 -> 1.54972e-06 diff=1.19e-07,1.19e-07 Linf=1.639e-07
#0: loss: 1.54972e-06 -> 1.31130e-06 diff=3.58e-07,3.58e-07 Linf=1.960e-07
#1: loss: 1.31130e-06 -> 8.34465e-07 diff=8.34e-07,8.34e-07 Linf=1.990e-07
#3: loss: 8.34465e-07 -> 7.15256e-07 diff=9.54e-07,9.54e-07 Linf=2.384e-07
#4: loss: 7.15256e-07 -> 5.96046e-07 diff=1.07e-06,1.07e-06 Linf=2.384e-07
#14: loss: 5.96046e-07 -> 4.76837e-07 diff=1.19e-06,1.19e-06 Linf=2.384e-07
#20: loss: 4.76837e-07 -> 3.57628e-07 diff=1.31e-06,1.31e-06 Linf=2.728e-07
#22: loss: 3.57628e-07 -> 2.38419e-07 diff=1.43e-06,1.43e-06 Linf=2.728e-07
#30: loss: 2.38419e-07 -> 1.19209e-07 diff=1.55e-06,1.55e-06 Linf=2.728e-07
#199: loss: 1.19209e-07 -> 0.00000e+00 diff=1.67e-06,1.67e-06 Linf=2.728e-07
#242: loss: 0.00000e+00 -> -1.19209e-07 diff=1.79e-06,1.79e-06 Linf=2.728e-07
#262: loss: -1.19209e-07 -> -2.38419e-07 diff=1.91e-06,1.91e-06 Linf=2.728e-07
#877: loss: -2.38419e-07 -> -3.57628e-07 diff=2.03e-06,2.03e-06 Linf=2.980e-07
conv [-4.98 -7.59  0.75 -1.23 -7.24 -9.37 -8.33  0.75 -2.24 -2.19] l=7 cw=1.43e-06
mm   [-4.98 -7.59  0.75 -1.23 -7.24 -9.37 -8.33  0.75 -2.24 -2.19] l=2 cw=-3.58e-07
test acc: 98.57%
working on output/mnist/7186.model with loss=3.0994415e-06
#0: loss: 3.09944e-06 -> 2.86102e-06 diff=2.38e-07,2.38e-07 Linf=1.818e-07
#0: loss: 2.86102e-06 -> 2.38419e-06 diff=7.15e-07,7.15e-07 Linf=1.818e-07
#1: loss: 2.38419e-06 -> 2.14577e-06 diff=9.54e-07,9.54e-07 Linf=1.818e-07
#14: loss: 2.14577e-06 -> 1.90735e-06 diff=1.19e-06,1.19e-06 Linf=1.818e-07
working on output/mnist/8571.model with loss=3.0994415e-06
#0: loss: 3.09944e-06 -> 2.62260e-06 diff=4.77e-07,4.77e-07 Linf=1.990e-07
#1: loss: 2.62260e-06 -> 2.38419e-06 diff=7.15e-07,7.15e-07 Linf=1.990e-07
#2: loss: 2.38419e-06 -> 2.14577e-06 diff=9.54e-07,9.54e-07 Linf=1.990e-07
#17: loss: 2.14577e-06 -> 1.66893e-06 diff=1.43e-06,1.43e-06 Linf=1.990e-07
#163: loss: 1.66893e-06 -> 1.43051e-06 diff=1.67e-06,1.67e-06 Linf=2.682e-07
#165: loss: 1.43051e-06 -> 1.19209e-06 diff=1.91e-06,1.91e-06 Linf=3.549e-07
#170: loss: 1.19209e-06 -> 9.53674e-07 diff=2.15e-06,2.15e-06 Linf=3.549e-07
working on output/mnist/41.model with loss=3.33786e-06
#0: loss: 3.33786e-06 -> 2.98023e-06 diff=3.58e-07,3.58e-07 Linf=2.086e-07
#1: loss: 2.98023e-06 -> 2.50340e-06 diff=8.34e-07,8.34e-07 Linf=2.086e-07
#1: loss: 2.50340e-06 -> 2.14577e-06 diff=1.19e-06,1.19e-06 Linf=2.086e-07
#8: loss: 2.14577e-06 -> 2.02656e-06 diff=1.31e-06,1.31e-06 Linf=2.384e-07
#9: loss: 2.02656e-06 -> 1.78814e-06 diff=1.55e-06,1.55e-06 Linf=2.384e-07
#10: loss: 1.78814e-06 -> 1.66893e-06 diff=1.67e-06,1.67e-06 Linf=2.384e-07
#35: loss: 1.66893e-06 -> 1.54972e-06 diff=1.79e-06,1.79e-06 Linf=2.764e-07
#620: loss: 1.54972e-06 -> 1.43051e-06 diff=1.91e-06,1.91e-06 Linf=2.980e-07
#645: loss: 1.43051e-06 -> 1.31130e-06 diff=2.03e-06,2.03e-06 Linf=2.980e-07
#678: loss: 1.31130e-06 -> 1.07288e-06 diff=2.26e-06,2.26e-06 Linf=2.980e-07
working on output/mnist/850.model with loss=3.4570694e-06
#0: loss: 3.45707e-06 -> 3.33786e-06 diff=1.19e-07,1.19e-07 Linf=1.788e-07
#1: loss: 3.33786e-06 -> 3.21865e-06 diff=2.38e-07,2.38e-07 Linf=1.788e-07
#1: loss: 3.21865e-06 -> 3.09944e-06 diff=3.58e-07,3.58e-07 Linf=2.110e-07
#11: loss: 3.09944e-06 -> 2.86102e-06 diff=5.96e-07,5.96e-07 Linf=2.110e-07
#11: loss: 2.86102e-06 -> 2.74181e-06 diff=7.15e-07,7.15e-07 Linf=2.110e-07
#15: loss: 2.74181e-06 -> 2.50340e-06 diff=9.54e-07,9.54e-07 Linf=2.110e-07
#16: loss: 2.50340e-06 -> 2.38419e-06 diff=1.07e-06,1.07e-06 Linf=2.110e-07
#17: loss: 2.38419e-06 -> 2.26498e-06 diff=1.19e-06,1.19e-06 Linf=2.110e-07
#20: loss: 2.26498e-06 -> 2.14577e-06 diff=1.31e-06,1.31e-06 Linf=2.110e-07
#66: loss: 2.14577e-06 -> 1.90735e-06 diff=1.55e-06,1.55e-06 Linf=2.591e-07
#536: loss: 1.90735e-06 -> 1.78814e-06 diff=1.67e-06,1.67e-06 Linf=2.591e-07
#539: loss: 1.78814e-06 -> 1.66893e-06 diff=1.79e-06,1.79e-06 Linf=4.074e-07
#540: loss: 1.66893e-06 -> 1.54972e-06 diff=1.91e-06,1.91e-06 Linf=4.359e-07
#545: loss: 1.54972e-06 -> 1.43051e-06 diff=2.03e-06,2.03e-06 Linf=4.359e-07
#562: loss: 1.43051e-06 -> 1.19209e-06 diff=2.26e-06,2.26e-06 Linf=4.359e-07
working on output/mnist/2782.model with loss=0.039580196
#0: loss: 3.95802e-02 -> 3.95800e-02 diff=1.49e-07,1.49e-07 Linf=1.788e-07
#0: loss: 3.95800e-02 -> 3.95799e-02 diff=2.98e-07,2.98e-07 Linf=1.937e-07
#0: loss: 3.95799e-02 -> 3.95797e-02 diff=4.77e-07,4.77e-07 Linf=1.937e-07
#0: loss: 3.95797e-02 -> 3.95795e-02 diff=7.15e-07,7.15e-07 Linf=1.937e-07
#0: loss: 3.95795e-02 -> 3.95794e-02 diff=8.34e-07,8.34e-07 Linf=1.937e-07
#2: loss: 3.95794e-02 -> 3.95793e-02 diff=8.64e-07,8.64e-07 Linf=2.384e-07
#2: loss: 3.95793e-02 -> 3.95793e-02 diff=8.94e-07,8.94e-07 Linf=2.384e-07
#4: loss: 3.95793e-02 -> 3.95791e-02 diff=1.13e-06,1.13e-06 Linf=2.384e-07
#17: loss: 3.95791e-02 -> 3.95790e-02 diff=1.16e-06,1.16e-06 Linf=2.533e-07
#21: loss: 3.95790e-02 -> 3.95790e-02 diff=1.19e-06,1.19e-06 Linf=3.145e-07
#28: loss: 3.95790e-02 -> 3.95789e-02 diff=1.31e-06,1.31e-06 Linf=3.145e-07
#38: loss: 3.95789e-02 -> 3.95787e-02 diff=1.52e-06,1.52e-06 Linf=3.576e-07
#39: loss: 3.95787e-02 -> 3.95786e-02 diff=1.55e-06,1.55e-06 Linf=3.576e-07
#40: loss: 3.95786e-02 -> 3.95784e-02 diff=1.79e-06,1.79e-06 Linf=3.576e-07
working on output/mnist/6791.model with loss=0.09271002
#0: loss: 9.27100e-02 -> 9.27097e-02 diff=3.58e-07,3.58e-07 Linf=1.639e-07
#0: loss: 9.27097e-02 -> 9.27093e-02 diff=7.15e-07,7.15e-07 Linf=2.384e-07
#0: loss: 9.27093e-02 -> 9.27092e-02 diff=8.34e-07,8.34e-07 Linf=2.384e-07
#0: loss: 9.27092e-02 -> 9.27091e-02 diff=9.54e-07,9.54e-07 Linf=2.384e-07
#1: loss: 9.27091e-02 -> 9.27088e-02 diff=1.19e-06,1.19e-06 Linf=2.384e-07
#1: loss: 9.27088e-02 -> 9.27087e-02 diff=1.31e-06,1.31e-06 Linf=2.384e-07
#14: loss: 9.27087e-02 -> 9.27086e-02 diff=1.43e-06,1.43e-06 Linf=2.384e-07
#37: loss: 9.27086e-02 -> 9.27082e-02 diff=1.79e-06,1.79e-06 Linf=2.384e-07
#71: loss: 9.27082e-02 -> 9.27081e-02 diff=1.97e-06,1.97e-06 Linf=2.384e-07
#81: loss: 9.27081e-02 -> 9.27080e-02 diff=2.03e-06,2.03e-06 Linf=2.384e-07
#106: loss: 9.27080e-02 -> 9.27079e-02 diff=2.15e-06,2.15e-06 Linf=2.384e-07
#170: loss: 9.27079e-02 -> 9.27078e-02 diff=2.26e-06,2.26e-06 Linf=2.384e-07
working on output/mnist/9285.model with loss=0.48362684
#0: loss: 4.83627e-01 -> 4.83627e-01 diff=1.19e-07,1.19e-07 Linf=1.788e-07
#0: loss: 4.83627e-01 -> 4.83627e-01 diff=2.38e-07,2.38e-07 Linf=1.788e-07
#0: loss: 4.83627e-01 -> 4.83626e-01 diff=5.96e-07,5.96e-07 Linf=1.788e-07
#4: loss: 4.83626e-01 -> 4.83626e-01 diff=7.15e-07,7.15e-07 Linf=2.980e-07
#6: loss: 4.83626e-01 -> 4.83626e-01 diff=8.34e-07,8.34e-07 Linf=2.980e-07
#7: loss: 4.83626e-01 -> 4.83626e-01 diff=1.07e-06,1.07e-06 Linf=2.980e-07
#9: loss: 4.83626e-01 -> 4.83626e-01 diff=1.19e-06,1.19e-06 Linf=2.980e-07
#113: loss: 4.83626e-01 -> 4.83626e-01 diff=1.31e-06,1.31e-06 Linf=2.980e-07
#115: loss: 4.83626e-01 -> 4.83625e-01 diff=1.43e-06,1.43e-06 Linf=2.980e-07
working on output/mnist/4798.model with loss=0.80837655
#0: loss: 8.08377e-01 -> 8.08376e-01 diff=2.38e-07,2.38e-07 Linf=1.714e-07
#4: loss: 8.08376e-01 -> 8.08376e-01 diff=4.77e-07,4.77e-07 Linf=1.714e-07
#7: loss: 8.08376e-01 -> 8.08376e-01 diff=7.15e-07,7.15e-07 Linf=1.714e-07
#8: loss: 8.08376e-01 -> 8.08376e-01 diff=9.54e-07,9.54e-07 Linf=2.682e-07
#9: loss: 8.08376e-01 -> 8.08375e-01 diff=1.19e-06,1.19e-06 Linf=2.682e-07
#57: loss: 8.08375e-01 -> 8.08375e-01 diff=1.31e-06,1.31e-06 Linf=2.682e-07
#664: loss: 8.08375e-01 -> 8.08375e-01 diff=1.55e-06,1.55e-06 Linf=2.682e-07
#689: loss: 8.08375e-01 -> 8.08375e-01 diff=1.67e-06,1.67e-06 Linf=2.980e-07
working on output/mnist/1459.model with loss=1.0982175
#0: loss: 1.09822e+00 -> 1.09822e+00 diff=2.38e-07,2.38e-07 Linf=1.788e-07
#2: loss: 1.09822e+00 -> 1.09822e+00 diff=3.58e-07,3.58e-07 Linf=1.968e-07
#3: loss: 1.09822e+00 -> 1.09822e+00 diff=4.77e-07,4.77e-07 Linf=1.968e-07
#22: loss: 1.09822e+00 -> 1.09822e+00 diff=5.96e-07,5.96e-07 Linf=2.683e-07
#27: loss: 1.09822e+00 -> 1.09822e+00 diff=7.15e-07,7.15e-07 Linf=2.683e-07
#46: loss: 1.09822e+00 -> 1.09822e+00 diff=8.34e-07,8.34e-07 Linf=3.521e-07
#190: loss: 1.09822e+00 -> 1.09822e+00 diff=9.54e-07,9.54e-07 Linf=3.576e-07
#190: loss: 1.09822e+00 -> 1.09822e+00 diff=1.07e-06,1.07e-06 Linf=3.576e-07
working on output/mnist/1212.model with loss=1.5184224
#0: loss: 1.51842e+00 -> 1.51842e+00 diff=4.77e-07,4.77e-07 Linf=2.384e-07
#1: loss: 1.51842e+00 -> 1.51842e+00 diff=7.15e-07,7.15e-07 Linf=2.384e-07
#1: loss: 1.51842e+00 -> 1.51842e+00 diff=1.19e-06,1.19e-06 Linf=2.384e-07
#1: loss: 1.51842e+00 -> 1.51842e+00 diff=1.43e-06,1.43e-06 Linf=2.384e-07
#1: loss: 1.51842e+00 -> 1.51842e+00 diff=1.67e-06,1.67e-06 Linf=2.384e-07
#54: loss: 1.51842e+00 -> 1.51842e+00 diff=1.91e-06,1.91e-06 Linf=2.384e-07
#54: loss: 1.51842e+00 -> 1.51842e+00 diff=2.15e-06,2.15e-06 Linf=2.384e-07
#235: loss: 1.51842e+00 -> 1.51842e+00 diff=2.38e-06,2.38e-06 Linf=2.384e-07
#237: loss: 1.51842e+00 -> 1.51842e+00 diff=2.62e-06,2.62e-06 Linf=2.384e-07
#242: loss: 1.51842e+00 -> 1.51842e+00 diff=2.86e-06,2.86e-06 Linf=2.384e-07
#251: loss: 1.51842e+00 -> 1.51842e+00 diff=3.10e-06,3.10e-06 Linf=2.627e-07
working on output/mnist/6576.model with loss=1.609463
#0: loss: 1.60946e+00 -> 1.60946e+00 diff=2.38e-07,2.38e-07 Linf=1.952e-07
#0: loss: 1.60946e+00 -> 1.60946e+00 diff=4.77e-07,4.77e-07 Linf=1.952e-07
#1: loss: 1.60946e+00 -> 1.60946e+00 diff=5.96e-07,5.96e-07 Linf=1.952e-07
#1: loss: 1.60946e+00 -> 1.60946e+00 diff=7.15e-07,7.15e-07 Linf=1.952e-07
#200: loss: 1.60946e+00 -> 1.60946e+00 diff=9.54e-07,9.54e-07 Linf=1.952e-07
#201: loss: 1.60946e+00 -> 1.60946e+00 diff=1.31e-06,1.31e-06 Linf=2.086e-07
#203: loss: 1.60946e+00 -> 1.60946e+00 diff=1.43e-06,1.43e-06 Linf=2.086e-07
#203: loss: 1.60946e+00 -> 1.60946e+00 diff=1.55e-06,1.55e-06 Linf=2.086e-07
#212: loss: 1.60946e+00 -> 1.60946e+00 diff=1.79e-06,1.79e-06 Linf=2.086e-07
#212: loss: 1.60946e+00 -> 1.60946e+00 diff=1.91e-06,1.91e-06 Linf=2.086e-07
#257: loss: 1.60946e+00 -> 1.60946e+00 diff=2.03e-06,2.03e-06 Linf=2.086e-07
working on output/mnist/6929.model with loss=1.8453515
#18: loss: 1.84535e+00 -> 1.84535e+00 diff=2.38e-07,2.38e-07 Linf=1.832e-07
#29: loss: 1.84535e+00 -> 1.84535e+00 diff=4.77e-07,4.77e-07 Linf=2.384e-07
#30: loss: 1.84535e+00 -> 1.84535e+00 diff=7.15e-07,7.15e-07 Linf=2.384e-07
#102: loss: 1.84535e+00 -> 1.84535e+00 diff=9.54e-07,9.54e-07 Linf=2.384e-07
#107: loss: 1.84535e+00 -> 1.84535e+00 diff=1.19e-06,1.19e-06 Linf=2.384e-07
working on output/mnist/1461.model with loss=2.0746448
#0: loss: 2.07464e+00 -> 2.07464e+00 diff=2.38e-07,2.38e-07 Linf=1.629e-07
#0: loss: 2.07464e+00 -> 2.07464e+00 diff=4.77e-07,4.77e-07 Linf=2.384e-07
#1: loss: 2.07464e+00 -> 2.07464e+00 diff=7.15e-07,7.15e-07 Linf=2.384e-07
#3: loss: 2.07464e+00 -> 2.07464e+00 diff=1.19e-06,1.19e-06 Linf=2.384e-07
#32: loss: 2.07464e+00 -> 2.07464e+00 diff=1.67e-06,1.67e-06 Linf=2.384e-07
working on output/mnist/2641.model with loss=2.2001748
#0: loss: 2.20017e+00 -> 2.20017e+00 diff=2.38e-07,2.38e-07 Linf=2.384e-07
#0: loss: 2.20017e+00 -> 2.20017e+00 diff=4.77e-07,4.77e-07 Linf=2.384e-07
#6: loss: 2.20017e+00 -> 2.20017e+00 diff=7.15e-07,7.15e-07 Linf=2.384e-07
#545: loss: 2.20017e+00 -> 2.20017e+00 diff=9.54e-07,9.54e-07 Linf=2.384e-07
working on output/mnist/3860.model with loss=3.6739755
#0: loss: 3.67398e+00 -> 3.67397e+00 diff=4.77e-07,4.77e-07 Linf=1.710e-07
#0: loss: 3.67397e+00 -> 3.67397e+00 diff=9.54e-07,9.54e-07 Linf=2.384e-07
#0: loss: 3.67397e+00 -> 3.67397e+00 diff=1.19e-06,1.19e-06 Linf=2.384e-07
#5: loss: 3.67397e+00 -> 3.67397e+00 diff=1.43e-06,1.43e-06 Linf=2.384e-07
#150: loss: 3.67397e+00 -> 3.67397e+00 diff=1.91e-06,1.91e-06 Linf=2.384e-07
