preprocessing on output/mnist/1212.model
adv_loss=4.827976226806641e-06 adv_loss_mm=4.708766937255859e-06 inp_loss=4.273808002471924 gap=-1.518417445762958
preprocessing on output/mnist/1459.model
adv_loss=1.430511474609375e-06 adv_loss_mm=2.6226043701171875e-06 inp_loss=4.129622459411621 gap=-1.0982149079709458
preprocessing on output/mnist/1461.model
adv_loss=4.649162292480469e-06 adv_loss_mm=3.5762786865234375e-06 inp_loss=3.348453998565674 gap=-2.074641341689596
preprocessing on output/mnist/2641.model
adv_loss=2.175569534301758e-06 adv_loss_mm=9.834766387939453e-07 inp_loss=3.137348175048828 gap=-2.2001739081808616
preprocessing on output/mnist/2782.model
adv_loss=3.4868717193603516e-06 adv_loss_mm=4.559755325317383e-06 inp_loss=3.4540224075317383 gap=-0.03957562719990185
preprocessing on output/mnist/3860.model
adv_loss=2.0265579223632812e-06 adv_loss_mm=3.337860107421875e-06 inp_loss=3.865034580230713 gap=-3.673972438462156
preprocessing on output/mnist/3966.model
adv_loss=4.172325134277344e-07 adv_loss_mm=8.940696716308594e-07 inp_loss=2.720130205154419 gap=-5.0190233333916646e-08
preprocessing on output/mnist/41.model
adv_loss=1.6093254089355469e-06 adv_loss_mm=3.159046173095703e-06 inp_loss=2.527251720428467 gap=-1.925067271937266e-07
preprocessing on output/mnist/4798.model
adv_loss=2.086162567138672e-06 adv_loss_mm=1.7285346984863281e-06 inp_loss=3.202497959136963 gap=-0.8083748030881506
preprocessing on output/mnist/6327.model
adv_loss=2.0563602447509766e-06 adv_loss_mm=1.1026859283447266e-06 inp_loss=3.2968909740448 gap=-2.081276688754929e-07
preprocessing on output/mnist/6576.model
adv_loss=1.3113021850585938e-06 adv_loss_mm=2.5033950805664062e-06 inp_loss=2.9622538089752197 gap=-1.6094605991540831
preprocessing on output/mnist/6791.model
adv_loss=2.6673078536987305e-06 adv_loss_mm=2.9653310775756836e-06 inp_loss=3.8554153442382812 gap=-0.09270705339313404
preprocessing on output/mnist/6929.model
adv_loss=2.5480985641479492e-06 adv_loss_mm=1.1175870895385742e-06 inp_loss=4.787816047668457 gap=-1.845350300828507
preprocessing on output/mnist/7186.model
adv_loss=3.337860107421875e-06 adv_loss_mm=2.2649765014648438e-06 inp_loss=3.554490327835083 gap=-7.865661580616019e-07
preprocessing on output/mnist/850.model
adv_loss=2.2649765014648438e-06 adv_loss_mm=8.344650268554688e-07 inp_loss=3.72520112991333 gap=-2.680255589217079e-06
preprocessing on output/mnist/8571.model
adv_loss=1.430511474609375e-06 adv_loss_mm=2.384185791015625e-06 inp_loss=3.511122703552246 gap=-7.943013895155949e-07
preprocessing on output/mnist/890.model
adv_loss=1.430511474609375e-06 adv_loss_mm=1.5497207641601562e-06 inp_loss=2.503289222717285 gap=-1.022442080828036e-07
preprocessing on output/mnist/9285.model
adv_loss=1.1920928955078125e-06 adv_loss_mm=2.384185791015625e-06 inp_loss=2.9720470905303955 gap=-0.48362446971144474
working on output/mnist/3966.model with loss=4.172325e-07
#2: loss: 4.17233e-07 -> 1.78814e-07 diff=2.38e-07,7.15e-07 Linf=2.384e-07
#2: loss: 1.78814e-07 -> 5.96046e-08 diff=3.58e-07,8.34e-07 Linf=2.384e-07
#6: loss: 5.96046e-08 -> -5.96046e-08 diff=4.77e-07,9.54e-07 Linf=2.384e-07
#21: loss: -5.96046e-08 -> -1.78814e-07 diff=5.96e-07,1.07e-06 Linf=2.384e-07
#25: loss: -1.78814e-07 -> -2.98023e-07 diff=7.15e-07,1.19e-06 Linf=2.682e-07
#26: loss: -2.98023e-07 -> -4.17233e-07 diff=8.34e-07,1.31e-06 Linf=2.682e-07
#34: loss: -4.17233e-07 -> -7.74860e-07 diff=1.19e-06,1.67e-06 Linf=2.682e-07
#35: loss: -7.74860e-07 -> -1.01328e-06 diff=1.43e-06,1.91e-06 Linf=2.682e-07
#47: loss: -1.01328e-06 -> -1.13249e-06 diff=1.55e-06,2.03e-06 Linf=2.682e-07
#52: loss: -1.13249e-06 -> -1.25170e-06 diff=1.67e-06,2.15e-06 Linf=2.682e-07
#133: loss: -1.25170e-06 -> -1.37091e-06 diff=1.79e-06,2.26e-06 Linf=2.682e-07
#135: loss: -1.37091e-06 -> -1.60933e-06 diff=2.03e-06,2.50e-06 Linf=2.682e-07
#144: loss: -1.60933e-06 -> -1.84774e-06 diff=2.26e-06,2.74e-06 Linf=2.682e-07
conv [-9.52 -4.02 -5.99 -3.45 -0.2  -5.1  -8.7  -3.2  -2.61 -0.2 ] l=4 cw=-1.85e-06
mm   [-9.52 -4.02 -5.99 -3.45 -0.2  -5.1  -8.7  -3.2  -2.61 -0.2 ] l=9 cw=1.49e-06
test acc: 98.57%
working on output/mnist/9285.model with loss=1.1920929e-06
#0: loss: 1.19209e-06 -> 9.53674e-07 diff=2.38e-07,1.43e-06 Linf=2.086e-07
#1: loss: 9.53674e-07 -> 8.34465e-07 diff=3.58e-07,1.55e-06 Linf=2.086e-07
#9: loss: 8.34465e-07 -> 7.15256e-07 diff=4.77e-07,1.67e-06 Linf=2.086e-07
#10: loss: 7.15256e-07 -> 5.96046e-07 diff=5.96e-07,1.79e-06 Linf=2.086e-07
#43: loss: 5.96046e-07 -> 4.76837e-07 diff=7.15e-07,1.91e-06 Linf=2.086e-07
#46: loss: 4.76837e-07 -> 3.57628e-07 diff=8.34e-07,2.03e-06 Linf=2.086e-07
#47: loss: 3.57628e-07 -> 1.19209e-07 diff=1.07e-06,2.26e-06 Linf=2.086e-07
working on output/mnist/6576.model with loss=1.3113022e-06
#0: loss: 1.31130e-06 -> 1.07288e-06 diff=2.38e-07,1.43e-06 Linf=1.764e-07
#5: loss: 1.07288e-06 -> 8.34465e-07 diff=4.77e-07,1.67e-06 Linf=2.384e-07
#11: loss: 8.34465e-07 -> 5.96046e-07 diff=7.15e-07,1.91e-06 Linf=2.384e-07
#17: loss: 5.96046e-07 -> 4.76837e-07 diff=8.34e-07,2.03e-06 Linf=2.384e-07
#18: loss: 4.76837e-07 -> 1.19209e-07 diff=1.19e-06,2.38e-06 Linf=2.384e-07
#21: loss: 1.19209e-07 -> 0.00000e+00 diff=1.31e-06,2.50e-06 Linf=2.384e-07
#542: loss: 0.00000e+00 -> -2.38419e-07 diff=1.55e-06,2.74e-06 Linf=2.384e-07
#545: loss: -2.38419e-07 -> -3.57628e-07 diff=1.67e-06,2.86e-06 Linf=2.384e-07
#577: loss: -3.57628e-07 -> -7.15256e-07 diff=2.03e-06,3.22e-06 Linf=2.384e-07
conv [-5.41 -5.69 -5.06  1.56 -7.76  1.56 -4.08 -9.97 -0.96 -1.74] l=3 cw=-7.15e-07
mm   [-5.41 -5.69 -5.06  1.56 -7.76  1.56 -4.08 -9.97 -0.96 -1.74] l=5 cw=4.05e-06
test acc: 98.36%
verification of original model failed: {'ObjectiveBound': 0.015727530233766253,
 'ObjectiveValue': nan,
 'PredictedIndex': 6,
 'SolveStatus': 'UserLimit',
 'SolveTime': 360.00348591804504,
 'TargetIndexes': array([ 1,  2,  3,  4,  5,  7,  8,  9, 10]),
 'TighteningApproach': array([[108],
       [112]], dtype=uint16),
 'TotalTime': 371.256164761,
 'robust': False,
 'status_known': False}
working on output/mnist/1459.model with loss=1.4305115e-06
#0: loss: 1.43051e-06 -> 1.37091e-06 diff=5.96e-08,1.25e-06 Linf=1.932e-07
#1: loss: 1.37091e-06 -> 1.25170e-06 diff=1.79e-07,1.37e-06 Linf=1.932e-07
#2: loss: 1.25170e-06 -> 1.07288e-06 diff=3.58e-07,1.55e-06 Linf=2.742e-07
#4: loss: 1.07288e-06 -> 1.01328e-06 diff=4.17e-07,1.61e-06 Linf=2.742e-07
#6: loss: 1.01328e-06 -> 8.34465e-07 diff=5.96e-07,1.79e-06 Linf=2.742e-07
#9: loss: 8.34465e-07 -> 7.74860e-07 diff=6.56e-07,1.85e-06 Linf=2.742e-07
#16: loss: 7.74860e-07 -> 7.15256e-07 diff=7.15e-07,1.91e-06 Linf=2.742e-07
#19: loss: 7.15256e-07 -> 4.76837e-07 diff=9.54e-07,2.15e-06 Linf=2.742e-07
#20: loss: 4.76837e-07 -> 4.17233e-07 diff=1.01e-06,2.21e-06 Linf=2.980e-07
#44: loss: 4.17233e-07 -> 2.38419e-07 diff=1.19e-06,2.38e-06 Linf=4.172e-07
#95: loss: 2.38419e-07 -> 0.00000e+00 diff=1.43e-06,2.62e-06 Linf=4.172e-07
#231: loss: 0.00000e+00 -> -5.96046e-08 diff=1.49e-06,2.68e-06 Linf=4.172e-07
#545: loss: -5.96046e-08 -> -2.38419e-07 diff=1.67e-06,2.86e-06 Linf=4.172e-07
#579: loss: -2.38419e-07 -> -2.98023e-07 diff=1.73e-06,2.92e-06 Linf=4.172e-07
#623: loss: -2.98023e-07 -> -3.57628e-07 diff=1.79e-06,2.98e-06 Linf=4.172e-07
#733: loss: -3.57628e-07 -> -5.36442e-07 diff=1.97e-06,3.16e-06 Linf=4.172e-07
conv [-4.66 -7.61 -4.96 -5.15  0.56 -7.   -6.98 -3.46 -3.16  0.56] l=9 cw=-5.36e-07
mm   [-4.66 -7.61 -4.96 -5.15  0.56 -7.   -6.98 -3.46 -3.16  0.56] l=4 cw=3.58e-06
test acc: 98.38%
verification of original model failed: {'ObjectiveBound': -1.8357031831284232e-06,
 'ObjectiveValue': -1.8357031831284232e-06,
 'PredictedIndex': 5,
 'SolveStatus': 'Optimal',
 'SolveTime': 10.842161178588867,
 'TargetIndexes': array([ 1,  2,  3,  4,  6,  7,  8,  9, 10]),
 'TighteningApproach': array([[108],
       [112]], dtype=uint16),
 'TotalTime': 22.31896256,
 'robust': False,
 'status_known': True}
retrying with new gap -1.0982142686843872 ...
conv [-4.66 -7.61 -4.96 -5.15  0.56 -7.   -6.98 -3.46 -3.16  0.56] l=4 cw=5.96e-08
mm   [-4.66 -7.61 -4.96 -5.15  0.56 -7.   -6.98 -3.46 -3.16  0.56] l=4 cw=4.17e-06
test acc: 98.38%
working on output/mnist/8571.model with loss=1.4305115e-06
#0: loss: 1.43051e-06 -> 1.19209e-06 diff=2.38e-07,1.19e-06 Linf=1.900e-07
#0: loss: 1.19209e-06 -> 9.53674e-07 diff=4.77e-07,1.43e-06 Linf=2.086e-07
#9: loss: 9.53674e-07 -> 7.15256e-07 diff=7.15e-07,1.67e-06 Linf=2.980e-07
#9: loss: 7.15256e-07 -> 0.00000e+00 diff=1.43e-06,2.38e-06 Linf=2.980e-07
working on output/mnist/890.model with loss=1.4305115e-06
#0: loss: 1.43051e-06 -> 1.31130e-06 diff=1.19e-07,2.38e-07 Linf=2.384e-07
#0: loss: 1.31130e-06 -> 1.07288e-06 diff=3.58e-07,4.77e-07 Linf=2.384e-07
#0: loss: 1.07288e-06 -> 3.57628e-07 diff=1.07e-06,1.19e-06 Linf=2.384e-07
#1: loss: 3.57628e-07 -> 2.38419e-07 diff=1.19e-06,1.31e-06 Linf=2.384e-07
#7: loss: 2.38419e-07 -> 1.19209e-07 diff=1.31e-06,1.43e-06 Linf=2.384e-07
#55: loss: 1.19209e-07 -> -1.19209e-07 diff=1.55e-06,1.67e-06 Linf=2.384e-07
#68: loss: -1.19209e-07 -> -2.38419e-07 diff=1.67e-06,1.79e-06 Linf=2.384e-07
#185: loss: -2.38419e-07 -> -3.57628e-07 diff=1.79e-06,1.91e-06 Linf=2.384e-07
conv [-4.98 -7.59  0.75 -1.23 -7.24 -9.37 -8.33  0.75 -2.24 -2.19] l=2 cw=-3.58e-07
mm   [-4.98 -7.59  0.75 -1.23 -7.24 -9.37 -8.33  0.75 -2.24 -2.19] l=7 cw=1.67e-06
test acc: 98.57%
working on output/mnist/41.model with loss=1.6093254e-06
#0: loss: 1.60933e-06 -> 1.01328e-06 diff=5.96e-07,2.15e-06 Linf=1.639e-07
#0: loss: 1.01328e-06 -> 8.94070e-07 diff=7.15e-07,2.26e-06 Linf=1.703e-07
#1: loss: 8.94070e-07 -> 6.55651e-07 diff=9.54e-07,2.50e-06 Linf=2.086e-07
#4: loss: 6.55651e-07 -> 4.17233e-07 diff=1.19e-06,2.74e-06 Linf=2.086e-07
#11: loss: 4.17233e-07 -> 1.78814e-07 diff=1.43e-06,2.98e-06 Linf=2.086e-07
#363: loss: 1.78814e-07 -> 5.96046e-08 diff=1.55e-06,3.10e-06 Linf=2.682e-07
working on output/mnist/3860.model with loss=2.026558e-06
#0: loss: 2.02656e-06 -> 1.54972e-06 diff=4.77e-07,1.79e-06 Linf=2.384e-07
#0: loss: 1.54972e-06 -> 1.07288e-06 diff=9.54e-07,2.26e-06 Linf=2.384e-07
#1: loss: 1.07288e-06 -> 9.53674e-07 diff=1.07e-06,2.38e-06 Linf=2.384e-07
#1: loss: 9.53674e-07 -> 8.34465e-07 diff=1.19e-06,2.50e-06 Linf=2.384e-07
#1: loss: 8.34465e-07 -> 7.15256e-07 diff=1.31e-06,2.62e-06 Linf=2.384e-07
#1: loss: 7.15256e-07 -> -4.76837e-07 diff=2.50e-06,3.81e-06 Linf=2.384e-07
#6: loss: -4.76837e-07 -> -5.96046e-07 diff=2.62e-06,3.93e-06 Linf=3.726e-07
#687: loss: -5.96046e-07 -> -7.15256e-07 diff=2.74e-06,4.05e-06 Linf=3.726e-07
conv [-8.86 -5.92 -1.9   0.88 -7.46 -1.99 -9.83  0.88 -1.39 -3.25] l=7 cw=-7.15e-07
mm   [-8.86 -5.92 -1.9   0.88 -7.46 -1.99 -9.83  0.88 -1.39 -3.25] l=3 cw=3.22e-06
test acc: 97.83%
working on output/mnist/6327.model with loss=2.0563602e-06
#0: loss: 2.05636e-06 -> 1.81794e-06 diff=2.38e-07,-7.15e-07 Linf=2.086e-07
#0: loss: 1.81794e-06 -> 1.57952e-06 diff=4.77e-07,-4.77e-07 Linf=2.086e-07
#0: loss: 1.57952e-06 -> 1.34110e-06 diff=7.15e-07,-2.38e-07 Linf=2.086e-07
#1: loss: 1.34110e-06 -> 8.64267e-07 diff=1.19e-06,2.38e-07 Linf=3.576e-07
#5: loss: 8.64267e-07 -> 6.25849e-07 diff=1.43e-06,4.77e-07 Linf=3.576e-07
#23: loss: 6.25849e-07 -> 3.87430e-07 diff=1.67e-06,7.15e-07 Linf=3.576e-07
#27: loss: 3.87430e-07 -> 2.98023e-08 diff=2.03e-06,1.07e-06 Linf=3.576e-07
#43: loss: 2.98023e-08 -> -8.94070e-08 diff=2.15e-06,1.19e-06 Linf=3.576e-07
#88: loss: -8.94070e-08 -> -3.27826e-07 diff=2.38e-06,1.43e-06 Linf=3.576e-07
#105: loss: -3.27826e-07 -> -4.47035e-07 diff=2.50e-06,1.55e-06 Linf=3.576e-07
conv [-3.97 -4.93 -4.93 -4.77 -5.1  -0.31 -2.56 -7.34 -0.31 -5.6 ] l=5 cw=-4.47e-07
mm   [-3.97 -4.93 -4.93 -4.77 -5.1  -0.31 -2.56 -7.34 -0.31 -5.6 ] l=8 cw=2.77e-06
test acc: 98.57%
working on output/mnist/4798.model with loss=2.0861626e-06
#0: loss: 2.08616e-06 -> 1.72853e-06 diff=3.58e-07,0.00e+00 Linf=1.863e-07
#0: loss: 1.72853e-06 -> 1.60933e-06 diff=4.77e-07,1.19e-07 Linf=1.863e-07
#0: loss: 1.60933e-06 -> 1.49012e-06 diff=5.96e-07,2.38e-07 Linf=1.937e-07
#0: loss: 1.49012e-06 -> 1.13249e-06 diff=9.54e-07,5.96e-07 Linf=1.937e-07
#0: loss: 1.13249e-06 -> 1.01328e-06 diff=1.07e-06,7.15e-07 Linf=1.937e-07
#2: loss: 1.01328e-06 -> 5.36442e-07 diff=1.55e-06,1.19e-06 Linf=3.874e-07
#129: loss: 5.36442e-07 -> 4.17233e-07 diff=1.67e-06,1.31e-06 Linf=3.874e-07
#142: loss: 4.17233e-07 -> 2.98023e-07 diff=1.79e-06,1.43e-06 Linf=3.874e-07
#940: loss: 2.98023e-07 -> 5.96046e-08 diff=2.03e-06,1.67e-06 Linf=3.874e-07
working on output/mnist/2641.model with loss=2.1755695e-06
#0: loss: 2.17557e-06 -> 1.93715e-06 diff=2.38e-07,-9.54e-07 Linf=1.964e-07
#0: loss: 1.93715e-06 -> 1.22190e-06 diff=9.54e-07,-2.38e-07 Linf=2.384e-07
#0: loss: 1.22190e-06 -> 9.83477e-07 diff=1.19e-06,0.00e+00 Linf=2.384e-07
#0: loss: 9.83477e-07 -> 7.45058e-07 diff=1.43e-06,2.38e-07 Linf=2.384e-07
#1: loss: 7.45058e-07 -> 6.25849e-07 diff=1.55e-06,3.58e-07 Linf=2.384e-07
#3: loss: 6.25849e-07 -> 3.87430e-07 diff=1.79e-06,5.96e-07 Linf=2.384e-07
#37: loss: 3.87430e-07 -> 2.68221e-07 diff=1.91e-06,7.15e-07 Linf=2.384e-07
#40: loss: 2.68221e-07 -> -2.08616e-07 diff=2.38e-06,1.19e-06 Linf=2.764e-07
#168: loss: -2.08616e-07 -> -3.27826e-07 diff=2.50e-06,1.31e-06 Linf=2.764e-07
#901: loss: -3.27826e-07 -> -4.47035e-07 diff=2.62e-06,1.43e-06 Linf=3.576e-07
#903: loss: -4.47035e-07 -> -5.66244e-07 diff=2.74e-06,1.55e-06 Linf=3.576e-07
#920: loss: -5.66244e-07 -> -6.85453e-07 diff=2.86e-06,1.67e-06 Linf=3.576e-07
#926: loss: -6.85453e-07 -> -8.04663e-07 diff=2.98e-06,1.79e-06 Linf=3.576e-07
conv [-6.83 -4.77 -4.53 -5.57 -3.72 -0.23 -0.23 -7.11 -1.89 -5.37] l=5 cw=-8.05e-07
mm   [-6.83 -4.77 -4.53 -5.57 -3.72 -0.23 -0.23 -7.11 -1.89 -5.37] l=6 cw=2.29e-06
test acc: 98.40%
working on output/mnist/850.model with loss=2.2649765e-06
#0: loss: 2.26498e-06 -> 2.14577e-06 diff=1.19e-07,-1.31e-06 Linf=1.788e-07
#0: loss: 2.14577e-06 -> 2.02656e-06 diff=2.38e-07,-1.19e-06 Linf=1.937e-07
#1: loss: 2.02656e-06 -> 1.90735e-06 diff=3.58e-07,-1.07e-06 Linf=1.937e-07
#3: loss: 1.90735e-06 -> 1.66893e-06 diff=5.96e-07,-8.34e-07 Linf=1.974e-07
working on output/mnist/6929.model with loss=2.5480986e-06
#0: loss: 2.54810e-06 -> 2.30968e-06 diff=2.38e-07,-1.19e-06 Linf=1.971e-07
#2: loss: 2.30968e-06 -> 2.07126e-06 diff=4.77e-07,-9.54e-07 Linf=1.971e-07
#3: loss: 2.07126e-06 -> 1.83284e-06 diff=7.15e-07,-7.15e-07 Linf=1.971e-07
#3: loss: 1.83284e-06 -> 1.59442e-06 diff=9.54e-07,-4.77e-07 Linf=1.971e-07
#4: loss: 1.59442e-06 -> 1.11759e-06 diff=1.43e-06,0.00e+00 Linf=2.012e-07
#133: loss: 1.11759e-06 -> 8.79169e-07 diff=1.67e-06,2.38e-07 Linf=2.980e-07
#477: loss: 8.79169e-07 -> 6.40750e-07 diff=1.91e-06,4.77e-07 Linf=2.980e-07
working on output/mnist/6791.model with loss=2.6673079e-06
#0: loss: 2.66731e-06 -> 2.42889e-06 diff=2.38e-07,5.36e-07 Linf=1.863e-07
#0: loss: 2.42889e-06 -> 2.30968e-06 diff=3.58e-07,6.56e-07 Linf=1.863e-07
#4: loss: 2.30968e-06 -> 2.07126e-06 diff=5.96e-07,8.94e-07 Linf=1.863e-07
#6: loss: 2.07126e-06 -> 2.01166e-06 diff=6.56e-07,9.54e-07 Linf=1.863e-07
#33: loss: 2.01166e-06 -> 1.83284e-06 diff=8.34e-07,1.13e-06 Linf=2.384e-07
#36: loss: 1.83284e-06 -> 1.59442e-06 diff=1.07e-06,1.37e-06 Linf=2.384e-07
#47: loss: 1.59442e-06 -> 1.53482e-06 diff=1.13e-06,1.43e-06 Linf=2.384e-07
#47: loss: 1.53482e-06 -> 1.47521e-06 diff=1.19e-06,1.49e-06 Linf=3.576e-07
#127: loss: 1.47521e-06 -> 1.35601e-06 diff=1.31e-06,1.61e-06 Linf=3.576e-07
working on output/mnist/7186.model with loss=3.33786e-06
#0: loss: 3.33786e-06 -> 2.26498e-06 diff=1.07e-06,0.00e+00 Linf=2.012e-07
#0: loss: 2.26498e-06 -> 2.02656e-06 diff=1.31e-06,2.38e-07 Linf=2.012e-07
#36: loss: 2.02656e-06 -> 1.90735e-06 diff=1.43e-06,3.58e-07 Linf=2.012e-07
#38: loss: 1.90735e-06 -> 1.66893e-06 diff=1.67e-06,5.96e-07 Linf=2.012e-07
#39: loss: 1.66893e-06 -> 1.43051e-06 diff=1.91e-06,8.34e-07 Linf=2.012e-07
#164: loss: 1.43051e-06 -> 9.53674e-07 diff=2.38e-06,1.31e-06 Linf=2.012e-07
#255: loss: 9.53674e-07 -> 8.34465e-07 diff=2.50e-06,1.43e-06 Linf=2.086e-07
working on output/mnist/2782.model with loss=3.4868717e-06
#0: loss: 3.48687e-06 -> 3.24845e-06 diff=2.38e-07,1.31e-06 Linf=1.937e-07
#0: loss: 3.24845e-06 -> 3.01003e-06 diff=4.77e-07,1.55e-06 Linf=1.937e-07
#2: loss: 3.01003e-06 -> 2.89083e-06 diff=5.96e-07,1.67e-06 Linf=1.937e-07
#6: loss: 2.89083e-06 -> 2.86102e-06 diff=6.26e-07,1.70e-06 Linf=3.523e-07
#10: loss: 2.86102e-06 -> 2.80142e-06 diff=6.85e-07,1.76e-06 Linf=3.523e-07
#12: loss: 2.80142e-06 -> 2.59280e-06 diff=8.94e-07,1.97e-06 Linf=3.523e-07
#13: loss: 2.59280e-06 -> 2.47359e-06 diff=1.01e-06,2.09e-06 Linf=3.523e-07
#17: loss: 2.47359e-06 -> 2.44379e-06 diff=1.04e-06,2.12e-06 Linf=3.523e-07
#17: loss: 2.44379e-06 -> 2.41399e-06 diff=1.07e-06,2.15e-06 Linf=3.523e-07
#22: loss: 2.41399e-06 -> 2.29478e-06 diff=1.19e-06,2.26e-06 Linf=4.954e-07
#29: loss: 2.29478e-06 -> 2.23517e-06 diff=1.25e-06,2.32e-06 Linf=4.954e-07
#58: loss: 2.23517e-06 -> 2.11596e-06 diff=1.37e-06,2.44e-06 Linf=4.954e-07
#74: loss: 2.11596e-06 -> 1.99676e-06 diff=1.49e-06,2.56e-06 Linf=4.954e-07
#98: loss: 1.99676e-06 -> 1.96695e-06 diff=1.52e-06,2.59e-06 Linf=4.954e-07
#875: loss: 1.96695e-06 -> 1.93715e-06 diff=1.55e-06,2.62e-06 Linf=4.954e-07
#885: loss: 1.93715e-06 -> 1.90735e-06 diff=1.58e-06,2.65e-06 Linf=4.954e-07
working on output/mnist/1461.model with loss=4.6491623e-06
#0: loss: 4.64916e-06 -> 4.41074e-06 diff=2.38e-07,-8.34e-07 Linf=1.892e-07
#1: loss: 4.41074e-06 -> 4.17233e-06 diff=4.77e-07,-5.96e-07 Linf=3.576e-07
#2: loss: 4.17233e-06 -> 3.93391e-06 diff=7.15e-07,-3.58e-07 Linf=3.576e-07
#879: loss: 3.93391e-06 -> 3.69549e-06 diff=9.54e-07,-1.19e-07 Linf=3.576e-07
working on output/mnist/1212.model with loss=4.827976e-06
#0: loss: 4.82798e-06 -> 4.35114e-06 diff=4.77e-07,3.58e-07 Linf=2.012e-07
#0: loss: 4.35114e-06 -> 4.11272e-06 diff=7.15e-07,5.96e-07 Linf=2.012e-07
#4: loss: 4.11272e-06 -> 3.87430e-06 diff=9.54e-07,8.34e-07 Linf=2.012e-07
#4: loss: 3.87430e-06 -> 3.63588e-06 diff=1.19e-06,1.07e-06 Linf=2.012e-07
#27: loss: 3.63588e-06 -> 3.51667e-06 diff=1.31e-06,1.19e-06 Linf=2.012e-07
#457: loss: 3.51667e-06 -> 3.39746e-06 diff=1.43e-06,1.31e-06 Linf=2.384e-07
